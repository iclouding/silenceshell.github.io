<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[伊布]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2015-12-08T13:26:38.133Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name><![CDATA[hubt@dtdream.com]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[fullnat系列（一）：到底什么时候需要用fullnat呢？]]></title>
    <link href="http://yoursite.com/2015/12/08/fullnat/"/>
    <id>http://yoursite.com/2015/12/08/fullnat/</id>
    <published>2015-12-08T12:36:38.000Z</published>
    <updated>2015-12-08T13:26:38.133Z</updated>
    <content type="html"><![CDATA[<p>来，我再写篇小水文。</p>
<p>服务器为了提高性能，通常会选择横向扩展，一般有2种做法：</p>
<ul>
<li>前置DNS服务器，同一个域名（Virtual Service）对应不同的真实服务器（Real Server），解析域名的时候，DNS服务器会轮询返回不同的服务器，这样真正提供服务的，就是不同的机器，达到负载分担的目的。</li>
<li>前置负载分担（LB）设备。可以是专业的LB设备，也可以是linux服务器开启LVS（4层）或者Nginx（7层）。LVS的使用可以参考前面的一篇文章。</li>
</ul>
<p>目前的发行版，内核默认会集成LVS module，可以自检下：<br><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@l<span class="title">vs ~]# lsmod |grep ip_vs</span><br><span class="line">ip_vs_wrr               2275</span>  <span class="number">4</span> </span><br><span class="line">ip_<span class="title">vs                 161155</span>  <span class="number">8</span> ip_<span class="title">vs_wrr</span><br><span class="line">ipv6</span>                  <span class="number">323428</span>  <span class="number">60</span> ip_<span class="title">vs,ip6</span>t_REJECT,<span class="label">nf_conntrack_ipv6</span>,<span class="label">nf_defrag_ipv6</span></span><br></pre></td></tr></table></figure></p>
<p>社区的linux发行版的LVS提供的报文转发模式有三种：NAT/DR/TUNNEL。阿里云SLB在NAT基础上还支持了FULLNAT模式，该模式在一般的开源版本中不提供，需要打补丁重新编译内核。在了解FULLNAT之前，我们先来看看NAT模式。</p>
<p><img src="http://7xir15.com1.z0.glb.clouddn.com/snat+dnat.png" alt=""></p>
<p>如上图。NAT模式对入报文做了DNAT，即将报文的目的地址改为RS的地址，但源地址不变；RS上配置路由策略（如网关），出报文到了LVS设备上后做SNAT，即将报文的源地址改为LVS设备上的地址，目的地址不变。NAT模式的劣势是必须要在RS上配置路由策略（其实还可以解决一个很重要的场景，下文会提到）。</p>
<p>而FULLNAT，顾名思义，就是在出入两个方向均做了SNAT+DNAT。<br><img src="http://7xir15.com1.z0.glb.clouddn.com/fullnat.png" alt=""><br>如上图。FULLNAT模式对入报文做了DNAT+SNAT，即将报文的目的地址改为RS的地址，源地址改为LVS设备地址；RS上不需要配置路由策略，出报文到了LVS设备上后做SNAT+DNAT，即将报文的源地址改为LVS设备上的地址，目的地址改为真实的用户地址。</p>
<p>一般来说，我们不需要使用FULLNAT，但是有一种场景，必须使用FULLNAT（或者类似的技术）：<br>通常LVS是为了解决外部访问集群内部的问题，但是在我们的一个生产环境上，我们遇到了必须在集群内部的server1，向server2/server3（提供sysdb）写log的场景。<br>server2/server3对外提供了VIP，用户可以从集群外部通过LVS来访问，但是server1访问sysdb的时候，会有路由问题。server1发出的syn报文，经由LVS转发给了server2，而server2应答的syn+ack报文，由于syn报文的源地址是server1，而server1跟server2在同一局域网内，所以server1会直接将该报文转发给server1，而不经过LVS。<br>所以就会不通。</p>
<p>有了fullnat，syn报文经过LVS的处理以后，源地址改为LVS的LIP(Local IP)、目的地址改为了server2的地址，所以，对于server2来说，该syn请求就是LVS发起的，所以syn+ack报文还是会应答给LVS服务器；而应答报文再经过LVS处理，源地址改为LVS的EIP(External IP)，目的地址改为server1的地址，所以对于server1来说，请求得到了正确的应答，连接可以建立。</p>
<p>fullnat解决了集群内部互相访问的问题。在阿里内部，应该还有更广阔的应用（例如虚机之间通信）。不过，据说青云曾经指出fullnat的一个弊端，即对于Real Server来说，无法审计真实的客户端，只能向LVS（阿里叫做SLB）请求。</p>
<p>下一篇文章讲如何给内核打fullnat补丁。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>来，我再写篇小水文。</p>
<p>服务器为了提高性能，通常会选择横向扩展，一般有2种做法：</p>
<ul>
<li>前置DNS服务器，同一个域名（Virtual Service）对应不同的真实服务器（Real Server），解析域名的时候，DNS服务器会轮询返回不同的]]>
    </summary>
    
      <category term="fullnat" scheme="http://yoursite.com/tags/fullnat/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[小玩意：如何让linux上挂死的进程重启？]]></title>
    <link href="http://yoursite.com/2015/11/11/task-restart/"/>
    <id>http://yoursite.com/2015/11/11/task-restart/</id>
    <published>2015-11-11T05:52:06.000Z</published>
    <updated>2015-11-11T06:08:13.410Z</updated>
    <content type="html"><![CDATA[<p>需求是这样的：我们在linux服务器上有一个采集进程，担心该进程出现故障挂死或者被人误杀，这种情况下需要能自动重启。使用peacemaker这样的分布式管理工具可以做到进程的监控，但毕竟体量较大，部署也稍嫌麻烦。<br>其实，使用keepalived就可以满足这种需求，部署起来也很简单，做个记录供以后查阅。</p>
<h3 id="1、安装keepalived">1、安装keepalived</h3><h3 id="2、配置keepalived检测">2、配置keepalived检测</h3><p>修改/etc/keepalived/keepalived.conf<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">vrrp_script</span> check_dtm &#123;</span><br><span class="line">    <span class="title">script</span> <span class="string">"/etc/keepalived/check_dtm.sh"</span></span><br><span class="line">    interval <span class="number">1</span></span><br><span class="line">    weight -<span class="number">5</span></span><br><span class="line">    fall <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    <span class="title">state</span> MASTER</span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id <span class="number">51</span></span><br><span class="line">    priority <span class="number">100</span></span><br><span class="line">    advert_int <span class="number">1</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        <span class="title">auth_type</span> PASS</span><br><span class="line">        auth_pass <span class="number">1111</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="title">track_script</span> &#123;</span><br><span class="line">       <span class="title">check_dtm</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如上配置，对VI_1实例配置track脚本，每秒检测一次，实际检测的脚本是check_dtm.sh。<br>由于我们只是使用keepalived的check功能，所以virtual_address和virtual_server的功能都不需要，相关配置全部删除。</p>
<h3 id="3、配置检测脚本check_dtm-sh">3、配置检测脚本<code>check_dtm.sh</code></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/bash</span></span><br><span class="line">ps aux|grep dtmonitor|grep java</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ $? != <span class="number">0</span> ] ; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"dtmonitor is down, try to restart."</span></span><br><span class="line">    bash /opt/dtmonitor/monitor/start.sh</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>真正做到重启的地方。简单来说，检查进程是否还在（当然可以做的粒度更准确一些，例如定时写一些文件之类），如果进程没了，则调用采集进程的启动脚本，尝试重启。</p>
<h3 id="4、采集进程的启动脚本。">4、采集进程的启动脚本。</h3><p>在采集进程的目录中（即/opt/dtmonitor/monitor/）编辑start.sh文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/bash</span><br><span class="line"></span></span><br><span class="line">CURDIR=<span class="string">"`dirname <span class="variable">$0</span>`"</span></span><br><span class="line">java -jar <span class="variable">$CURDIR</span>/dtmonitor.jar &amp;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"dtmonitor is started."</span></span><br></pre></td></tr></table></figure></p>
<p>注意当前目录的切换。</p>
<p>如上，启动keepalived服务后，杀死dtmonitor进程，可以观察到1s左右dtmonitor进程被keepalived服务重启了。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>需求是这样的：我们在linux服务器上有一个采集进程，担心该进程出现故障挂死或者被人误杀，这种情况下需要能自动重启。使用peacemaker这样的分布式管理工具可以做到进程的监控，但毕竟体量较大，部署也稍嫌麻烦。<br>其实，使用keepalived就可以满足这种需求，部署]]>
    </summary>
    
      <category term="keepalived" scheme="http://yoursite.com/tags/keepalived/"/>
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HBase系列（一）]]></title>
    <link href="http://yoursite.com/2015/09/16/hbase-1/"/>
    <id>http://yoursite.com/2015/09/16/hbase-1/</id>
    <published>2015-09-16T02:57:04.000Z</published>
    <updated>2015-09-16T03:13:42.749Z</updated>
    <content type="html"><![CDATA[<p>最近由于工作关系，需要了解HBase，随手记录一些内容，以供查阅。</p>
<h3 id="NoSQL">NoSQL</h3><p>在刚接触Hadoop的时候，对Hive和HBase这两个组件总是不算特别清楚，都跟数据库有点关系，Hive又跟HBase有依赖，扯不太清楚。<br>如果要简单的说二者的区别，可以这样理解：可以把Hive理解为一个SQL Parser，其目的是为了方便那些会使用SQL编程的数据科学家们，但真正在跑的，是Hive翻译出来的Map Reduce程序。所以Hive的用处仍然是离线批量计算。<br>而HBase本质上是一个NoSQL数据库。那么问题来了，NoSQL又是什么鬼？说白了，NoSQL(Not Only SQL)也是一种数据库；但它区别于Oracle、MySQL这种会提供一个便捷的SQL编程语言的关系型数据库。NoSQL通常是列式数据库，不支持事务，不提供行的修改，其访问接口与SQL完全不同，例如HBase的接口是这样的:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">001</span>:<span class="number">0</span>&gt; create <span class="string">'test'</span>, <span class="string">'cf'</span></span><br><span class="line"><span class="number">0</span> row(s) <span class="keyword">in</span> <span class="number">0.4170</span> seconds</span><br><span class="line"></span><br><span class="line">=&gt; Hbase::Table - <span class="built_in">test</span></span><br><span class="line">hbase(main):<span class="number">002</span>:<span class="number">0</span>&gt; list <span class="string">'test'</span></span><br><span class="line">TABLE</span><br><span class="line"><span class="built_in">test</span></span><br><span class="line"><span class="number">1</span> row(s) <span class="keyword">in</span> <span class="number">0.0180</span> seconds</span><br><span class="line"></span><br><span class="line">=&gt; [<span class="string">"test"</span>]</span><br></pre></td></tr></table></figure></p>
<p>显然这与SQL是不兼容的。当然了，这样做是不是合适也见仁见智。与SQL不兼容，必然造成用户原有业务系统不能方便的迁移到HBase上来，需要做较多的改造。但话说回来，由于NoSQL不能完整支持RDBMS的众多方便的功能，与其削足适履，不如干脆重开一片新天地。<br>如果您的业务想在HBase基础上开发一款新产品，可能做一套方便的SQL接口是个不错的方法。</p>
<h3 id="HBase">HBase</h3><p>从技术上来说，HBase应该叫做分布式“数仓”（Data Store），而不是数据库，因为它没有数据库的各种特点，例如列的类型，二级索引，触发器等。<br>HBase的特点如下：</p>
<ul>
<li>支持读写一致性。    这跟一些NoSQL数据库不太一样。</li>
<li>自动碎片化。HBase通过region实现分布式，region自动分片，并且随着数据的增长，会自动重新分布式。</li>
<li>Region Server支持故障恢复</li>
<li>集成HDFS，因此也就拥有了超大的存储空间</li>
<li>支持MR大数据量并发处理的源或目的</li>
<li>提供JAVA API（再也不用写Hibernate了）</li>
<li>对于非JAVA程序，HBase也提供Thrift/REST API</li>
<li>支持块存储和Bloom Filters</li>
<li>内置WEB化管理界面(呵呵)</li>
</ul>
<h3 id="快速开始">快速开始</h3><p>我们先在本地stand alone的状态启动一个HBase的环境（没有集成HDFS，只是体验用）。官方说明，只要10分钟就能搞定。这个例子会帮助我们对HBase有个比较感性的认识。</p>
<ol>
<li><p>JDK<br>由于版权的问题，以后我们都会只用openjdk。如下分别安装JRE和JDK。</p>
<figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor"># yum install java-1.8.0-openjdk</span></span><br><span class="line"><span class="preprocessor"># yum install java-1.8.0-openjdk-devel</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>去官网或者<a href="http://www.apache.org/dyn/closer.lua/hbase/" target="_blank" rel="external">镜像</a>下载stable bin，解压。</p>
</li>
<li><p>从 0.98.5 开始要求设置JAVA_HOME环境变量。<br>有两种做法：<br>一是设置全局的JAVA_HOME，这样所有的hadoop组件都可以得到满足，但是如果你想支持多套JDK环境就没法应付了。<br>二是在hbase_env.sh中单独设置本组件的JAVA_HOME，精细化管理。我们采用的是这个做法。编辑./conf/hbase_env.sh文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The java implementation to use.  Java 1.7+ required.</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如果你的环境跟我不一样也没关系，只是要注意从上面给出的路径直接走到<code>./bin</code>可以找到javac。</p>
<ol>
<li>设置hbase的使用的目录。<br>还记得我们是standalone模式安装吗？这种情况实际我们数据是存储在本地的某个目录的（对应集群则存储在HDFS）。在<code>conf/hbase-site.xml</code>中新增如下：</li>
</ol>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">value</span>&gt;</span>file:///home/testuser/hbase<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">value</span>&gt;</span>/home/testuser/zookeeper<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>hbase和zookeper两个目录不需要创建。</p>
<ol>
<li>启动HBase服务<br>HBase提供了脚本<code>bin/start-hbase.sh</code>，可以方便的启动HBase服务。启动成功后，如果你输入jps，只会看到一个HMaster的进程。<figure class="highlight vala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="preprocessor"># jps</span></span><br><span class="line"><span class="number">3030</span> Jps</span><br><span class="line"><span class="number">1997</span> HMaster</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>standalone模式里，HBase在一个JVM中运行了HMaster、Region Server、zookeeper三个角色。</p>
<ol>
<li>进入到HBase shell交互界面：</li>
</ol>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ./bin/hbase shell</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">09</span>-<span class="number">15</span> <span class="number">02</span>:<span class="number">08</span>:<span class="number">38</span>,<span class="number">364</span> WARN  [main] util.NativeCodeLoader: Unable <span class="built_in">to</span> <span class="built_in">load</span> native-hadoop library <span class="keyword">for</span> your <span class="built_in">platform</span>... <span class="keyword">using</span> builtin-java classes where applicable</span><br><span class="line">HBase Shell; enter <span class="string">'help&lt;RETURN&gt;'</span> <span class="keyword">for</span> list <span class="operator">of</span> supported commands.</span><br><span class="line">Type <span class="string">"exit&lt;RETURN&gt;"</span> <span class="built_in">to</span> leave <span class="operator">the</span> HBase Shell</span><br><span class="line">Version <span class="number">1.1</span>.2, rcc2b70cf03e3378800661ec5cab11eb43fafe0fc, Wed Aug <span class="number">26</span> <span class="number">20</span>:<span class="number">11</span>:<span class="number">27</span> PDT <span class="number">2015</span></span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">001</span>:<span class="number">0</span>&gt;</span><br></pre></td></tr></table></figure>
<p>在这儿你可以创建表、插入数据、查询数据等，官方网站上有，我直接搬运过来好了。唯一需要注意的是这个例子用了列族(就是cf:a, cf:b, cf:c，下一篇文章再谈)等。</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">001</span>:<span class="number">0</span>&gt; create <span class="string">'test'</span>, <span class="string">'cf'</span></span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">002</span>:<span class="number">0</span>&gt; list <span class="string">'test'</span></span><br><span class="line">TABLE</span><br><span class="line">test</span><br><span class="line"><span class="number">1</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">0.0180</span> seconds</span><br><span class="line"></span><br><span class="line">=&gt; [<span class="string">"test"</span>]</span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">003</span>:<span class="number">0</span>&gt; put <span class="string">'test'</span>, <span class="string">'row1'</span>, <span class="string">'cf:a'</span>, <span class="string">'value1'</span></span><br><span class="line"><span class="number">0</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">0.0850</span> seconds</span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">004</span>:<span class="number">0</span>&gt; put <span class="string">'test'</span>, <span class="string">'row2'</span>, <span class="string">'cf:b'</span>, <span class="string">'value2'</span></span><br><span class="line"><span class="number">0</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">0.0110</span> seconds</span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">005</span>:<span class="number">0</span>&gt; put <span class="string">'test'</span>, <span class="string">'row3'</span>, <span class="string">'cf:c'</span>, <span class="string">'value3'</span></span><br><span class="line"><span class="number">0</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">0.0100</span> seconds</span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">006</span>:<span class="number">0</span>&gt; scan <span class="string">'test'</span></span><br><span class="line">ROW                                      COLUMN+CELL</span><br><span class="line"> row1                                    column=cf:<span class="tag">a</span>, timestamp=<span class="number">1421762485768</span>, value=value1</span><br><span class="line"> row2                                    column=cf:<span class="tag">b</span>, timestamp=<span class="number">1421762491785</span>, value=value2</span><br><span class="line"> row3                                    column=cf:c, timestamp=<span class="number">1421762496210</span>, value=value3</span><br><span class="line"><span class="number">3</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">0.0230</span> seconds</span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">007</span>:<span class="number">0</span>&gt; get <span class="string">'test'</span>, <span class="string">'row1'</span></span><br><span class="line">COLUMN                                   CELL</span><br><span class="line"> cf:<span class="tag">a</span>                                    timestamp=<span class="number">1421762485768</span>, value=value1</span><br><span class="line"><span class="number">1</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">0.0350</span> seconds</span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">008</span>:<span class="number">0</span>&gt; disable <span class="string">'test'</span></span><br><span class="line"><span class="number">0</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">1.1820</span> seconds</span><br><span class="line"><span class="function"><span class="title">hbase</span><span class="params">(main)</span></span>:<span class="number">011</span>:<span class="number">0</span>&gt; drop <span class="string">'test'</span></span><br><span class="line"><span class="number">0</span> <span class="function"><span class="title">row</span><span class="params">(s)</span></span> <span class="keyword">in</span> <span class="number">0.1370</span> seconds</span><br></pre></td></tr></table></figure>
<p><a href="http://hbase.apache.org/book.html#quickstart" target="_blank" rel="external">HBase 官方链接</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>最近由于工作关系，需要了解HBase，随手记录一些内容，以供查阅。</p>
<h3 id="NoSQL">NoSQL</h3><p>在刚接触Hadoop的时候，对Hive和HBase这两个组件总是不算特别清楚，都跟数据库有点关系，Hive又跟HBase有依赖，扯不太清楚。<]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[mysql:C源代码内嵌SQL语句的预编译工具]]></title>
    <link href="http://yoursite.com/2015/09/07/mysql-ec/"/>
    <id>http://yoursite.com/2015/09/07/mysql-ec/</id>
    <published>2015-09-07T11:58:40.000Z</published>
    <updated>2015-09-11T03:08:18.170Z</updated>
    <content type="html"><![CDATA[<p><strong>本文较水  哪篇不水</strong></p>
<p>今天遇到一个比较好玩的东西，记下来跟大家分享。<br>我们知道操作数据库，在JAVA环境中一般会使用JDBC，不管是mysql、oracle还是别的什么数据库都可以比较好的支持；但在一些比较古老（或者说比较谨慎）的系统中，比如银行业，可能其应用使用的还是C语言写的，这种情况JDBC是没门了，只能调用对应数据库提供的C lib，例如mysql的C库提供了这些接口：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MYSQL *mysql_init(MYSQL *mysql)</span><br><span class="line">MYSQL *mysql_real_connect(MYSQL *mysql, <span class="keyword">const</span> <span class="keyword">char</span> *host, <span class="keyword">const</span> <span class="keyword">char</span> *user, <span class="keyword">const</span> <span class="keyword">char</span> *passwd, <span class="keyword">const</span> <span class="keyword">char</span> *db, <span class="keyword">unsigned</span> <span class="keyword">int</span> port, <span class="keyword">const</span> <span class="keyword">char</span> *unix_socket, <span class="keyword">unsigned</span> <span class="keyword">long</span> client_flag)</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mysql_query</span><span class="params">(MYSQL *mysql, <span class="keyword">const</span> <span class="keyword">char</span> *stmt_str)</span></span></span><br></pre></td></tr></table></figure></p>
<p>有了C库，按照一般的思路，直接在C里面调用对应的API就好了，但显然这样不如直接写SQL方便。于是像Oracle就提供了<a href="http://baike.baidu.com/link?url=GeQqyf0TdG0m3EWrFIVO7LIw8yUsjzAFA7E4VKm_s21kOWD2rePSmVCKCyUWT5GGdKm-v8EJ8U0HWZMZGmlv8K" target="_blank" rel="external">Pro*C</a>这种工具。<br>说白了PRO*C就是一种预编译工具，我们写的代码是C和SQL混合的，这样的代码没办法直接编译，gcc不认。PRO<em>C会将该代码（</em>.pc）转为纯C代码，这样就可以用gcc编译为可执行文件了。但PRO*C是为ORACLE服务的，编译出来的代码调用的也是ORACLE的C库，显然我们想给mysql用是行不通的，需要一款类似的工具。其他的数据库，如IBM DB2有PREP，Informix和Postgre SQL Server都有自己的ESQL/C工具。</p>
<p>在网上扒了半天，找到了这么一个工具，<a href="http://sourceforge.net/projects/open-esql/" target="_blank" rel="external">open esql</a>。下载下来解压后看到两个文件夹，e2odbc是使用ODBC，理论上应该适应所有类型的数据库，而e2mysql是我们要用的。进到e2mysql看到有三个文件：<code>e2mysql.awk  e2mysql.cpp  e2mysql.h</code>。e2mysql.awk是一个awk脚本，用来预处理pc混合文件；e2mysql.cpp用来定义数据库连接信息。</p>
<p>使用步骤如下：</p>
<p><strong>1、使用awk脚本转换pc文件为C++文件。</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># awk -f e2mysql.awk xxx.pc &gt; xxx.cpp</span></span><br></pre></td></tr></table></figure></p>
<p>预处理实际就是文本转换处理，正是awk的用武之地。</p>
<p><strong>2、将xxx.cpp与e2mysql.cpp一起编译。</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># g++ xxx.cpp e2mysql.cpp -o xxx `mysql_config --cflags --libs`</span></span><br></pre></td></tr></table></figure></p>
<p>步骤很简单，但过程中遇到了一些问题，这里记一下，您自己解决起来应该也比较简单。<br>1、g++编译的时候提示没有sqlda.h、sqlcpr.h。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xxx.cpp:<span class="number">7</span>:<span class="number">21</span>: error: sqlda.h: No such file or directory</span><br><span class="line">xxx.cpp:<span class="number">8</span>:<span class="number">20</span>: warning: extra tokens at end of <span class="preprocessor">#include directive</span></span><br><span class="line">xxx.cpp:<span class="number">8</span>:<span class="number">22</span>: error: sqlcpr.h: No such file or directory</span><br></pre></td></tr></table></figure></p>
<p>PRO*C的源文件里会调用这两个头文件，我们没有，删掉即可。如果是在生产环境，建议创建这两个头文件，为空即可。</p>
<p>2、提示e2mysql.h里没有定义strlen。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">e2mysql.h: In function ‘<span class="function"><span class="keyword">int32_t</span> <span class="title">SQLBindParmPoly</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">string</span>&amp;, <span class="keyword">const</span> <span class="keyword">char</span>*, <span class="keyword">char</span>, <span class="keyword">uint16_t</span>)</span>’:</span><br><span class="line">e2mysql.h:176: error: ‘<span class="built_in">strlen</span>’ was not declared in <span class="keyword">this</span> scope</span></span><br></pre></td></tr></table></figure></p>
<p>strlen是C的string函数，需要包含cstring头文件：<code>#include &lt;cstring&gt;</code>。</p>
<p>3、提示e2mysql.h里没有定义atoi。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">e2mysql.h: In function ‘<span class="function"><span class="keyword">int32_t</span> <span class="title">SQLBindColPoly</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>*, <span class="keyword">int16_t</span>&amp;, <span class="keyword">uint16_t</span>)</span>’:</span><br><span class="line">e2mysql.h:319: error: ‘atoi’ was not declared in <span class="keyword">this</span> scope</span></span><br></pre></td></tr></table></figure></p>
<p>atoi是stdlib里的函数，需要包含该头文件：<code>#include &lt;stdlib.h&gt;</code>。</p>
<p>4、提示EXEC不识别。<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xxx.cpp:<span class="number">13</span>: <span class="keyword">error</span>: ‘EXEC’ <span class="keyword">does</span> <span class="keyword">not</span> <span class="property">name</span> a type</span><br></pre></td></tr></table></figure></p>
<p>找到代码里是这一句：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*RELEASE_CURSOR=YES 使PROC 在执行完后释放与嵌入SQL有关资源*/</span></span><br><span class="line">EXEC ORACLE OPTION (RELEASE_CURSOR = YES);</span><br></pre></td></tr></table></figure></p>
<p>显然这句是跟ORACLE相关的，工具不认。我这里粗暴的将这句注释掉了。</p>
<p>5、提示使用了int16类型不识别。<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xxx.cpp:<span class="number">33</span>: <span class="keyword">error</span>: ‘int16’ <span class="keyword">does</span> <span class="keyword">not</span> <span class="property">name</span> a type</span><br><span class="line">xxx.cpp:<span class="number">61</span>: <span class="keyword">error</span>: ‘int16’ <span class="keyword">does</span> <span class="keyword">not</span> <span class="property">name</span> a type</span><br><span class="line">xxx.cpp:<span class="number">78</span>: <span class="keyword">error</span>: ‘int16’ <span class="keyword">does</span> <span class="keyword">not</span> <span class="property">name</span> a type</span><br></pre></td></tr></table></figure></p>
<p>应该是作者的环境不是gcc，而是一些能认int16这种变体的windows环境。这个是在awk预编译的时候生成的，需要改awk脚本源码，我这里是整体替换为了short int。</p>
<p>6、提示sqlca_struct里没有sqlerrm。<br><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xxx<span class="class">.cpp</span>: In function ‘void <span class="function"><span class="title">sql_error</span><span class="params">(char*)</span></span>’:</span><br><span class="line">xxx<span class="class">.cpp</span>:<span class="number">92</span>: error: ‘struct sqlca_struct’ has no member named ‘sqlerrm’</span><br></pre></td></tr></table></figure></p>
<p>如上，sqlca是oracle特有的，这儿不识别，注释掉即可。</p>
<p>7、编译成功，执行的时候提示连不上<code>&#39;abc.xyz.com&#39;</code>。<br>看了下awk脚本，没有对connect做转换，而e2mysql.cpp里有个SQLHelperConnect(void)函数，里面可以修改数据库连接信息，改之，重新编译，验证OK。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ./xxx</span></span><br><span class="line">Connecting to database</span><br><span class="line">Connected: <span class="built_in">test</span></span><br><span class="line">c1=<span class="number">100</span>,c2=<span class="number">200</span>,c3=<span class="number">300</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from xxx;</span><br><span class="line">+------+------+------+</span><br><span class="line">| c1   | c2   | c3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">|  <span class="number">100</span> |  <span class="number">200</span> |  <span class="number">300</span> |</span><br><span class="line">+------+------+------+</span><br><span class="line"><span class="number">1</span> row <span class="keyword">in</span> <span class="built_in">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p>8、如果提示没有mysql.h，或者找不到mysqlclient的lib，建议安装mysql-devel(centos 6.5)，并且在编译的时候，不要手工指定-I、-L、-lmysqlclient，而是用mysql_config自动配置：<code>mysql_config --cflags --libs</code>。</p>
<p>总的来说这个脚本在不复杂的情况下还是能用的，但确实不成熟，如果有大量的C文件，需要一个一个去转，而且每个文件可能都要做一些修改；没能像PRO*C那样可以返回SQL执行的结果，用户用起来不方便；等等。解决问题的思路没错，但如果要商业化，还是有很长的路要走。</p>
<p>所有源文件放到github上了，参见<a href="https://github.com/silenceshell/open-esql-s" target="_blank" rel="external">open-esql-s</a>。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p><strong>本文较水  哪篇不水</strong></p>
<p>今天遇到一个比较好玩的东西，记下来跟大家分享。<br>我们知道操作数据库，在JAVA环境中一般会使用JDBC，不管是mysql、oracle还是别的什么数据库都可以比较好的支持；但在一些比较古老（或者说比]]>
    </summary>
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用lvs+keepalived为mysql提供高可靠的负载分担功能]]></title>
    <link href="http://yoursite.com/2015/08/20/dlvs/"/>
    <id>http://yoursite.com/2015/08/20/dlvs/</id>
    <published>2015-08-20T07:29:34.000Z</published>
    <updated>2015-08-22T05:38:54.373Z</updated>
    <content type="html"><![CDATA[<h3 id="需求">需求</h3><h3 id="1_安装软件">1 安装软件</h3><p>基本所有的Linux版本内核都包含了LVS，不需要再安装。<br>安装ipvsadm，用来控制内核lvs表项；<br>keepalived，用来控制虚IP迁移；<br>ldirectord，现在还没有用到。可以用来检测real server是否可用。<br>我用的是centos，直接yum安装即可。</p>
<h3 id="2_组网">2 组网</h3><p>使用了4台虚拟机，本机连接到其中虚拟机里的mysql服务。<br>组网图如下。<br><img src="http://7xir15.com1.z0.glb.clouddn.com/SLB_LVS.png" alt=""></p>
<h3 id="3_配置keepalived">3 配置keepalived</h3><p>需要在DLVS1、DLVS2两台服务器上配置keepalived。keepalived需要配置2个VRRP实例：<br>VRRP实例1:供外部用户访问，DLVS故障恢复不影响用户访问，对应虚IP1；<br>VRRP实例2：供mysql服务器访问。由于在本例中lvs配置成nat模式，mysql集群上的各个机器需要配置网关为DLVS的内部虚IP，否则DLVS迁移后，mysql上报文回不去。对应虚IP2，即Real Server(RS)的网关地址。<br>其中，DLVS1的priority均配置为101，DLVS2的priority均配置为100。DLVS1、DLVS2均正常时，DLVS1优先级更高，所以虚IP落在DLVS1上；若DLVS1故障，VRRP迁移，虚IP改落在DLVS2上；DLVS1故障恢复后，会抢占回虚IP。</p>
<blockquote>
<p>由于两台服务器配置基本是一致的，为了避免发生过多的虚IP迁移，这里我们把VRRP配置为不抢占模式。<br>具体到配置上，两台设备均配置VRRP state为BACKUP（当然这样会有一个影响，因为现在没有MASTER，启动以后要稍等一会才会抢占虚IP）；计划为主的设备，VRRPpriority配置更大，并且添加nopreempt。备设备不需要再加preempt。</p>
</blockquote>
<p>/etc/keepalived/keepalived.conf：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line">global_defs &#123;</span><br><span class="line">   <span class="comment">#不做修改</span></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface eth2</span><br><span class="line">    virtual_router_id <span class="number">51</span></span><br><span class="line">    priority <span class="number">101</span></span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int <span class="number">1</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_<span class="built_in">type</span> PASS</span><br><span class="line">        auth_pass <span class="number">1111</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        <span class="number">192.168</span>.<span class="number">80.111</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface eth1</span><br><span class="line">    virtual_router_id <span class="number">52</span></span><br><span class="line">    priority <span class="number">101</span></span><br><span class="line">    nopreempt</span><br><span class="line">    advert_int <span class="number">1</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_<span class="built_in">type</span> PASS</span><br><span class="line">        auth_pass <span class="number">1111</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        <span class="number">10.80</span>.<span class="number">1.243</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里我没有检查LVS服务是否可靠。DLVS进程起来以后，keepalived需要脚本检查DLVS进程是否正常，如果故障了需要切换。怎么设置参考我之前的<a href="http://www.datastart.cn/2015/07/02/nginx-keepalived/" target="_blank" rel="external">文章</a>。</p>
<h3 id="4_配置RS">4 配置RS</h3><p>RS上主要配置MySQL和网络：<br>1、安装及配置MySQL。安装不再赘述，需要配置MySQL远程访问及root密码：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'root'</span>@<span class="string">'%'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'123456'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span></span><br><span class="line"><span class="operator"><span class="keyword">FLUSH</span> <span class="keyword">PRIVILEGES</span>;</span></span><br></pre></td></tr></table></figure></p>
<p>2、配置网络<br>centos的配置文件在<code>/etc/sysconfig/network-scripts/ifcfg-ethx</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=<span class="string">"eth0"</span></span><br><span class="line">BOOTPROTO=<span class="string">"static"</span></span><br><span class="line">IPV6INIT=<span class="string">"yes"</span></span><br><span class="line">NM_CONTROLLED=<span class="string">"yes"</span></span><br><span class="line">IPADDR=<span class="number">192.168</span>.<span class="number">80.136</span></span><br><span class="line">NETMASK=<span class="number">255.255</span>.<span class="number">255.0</span></span><br><span class="line">GATEWAY=<span class="number">192.168</span>.<span class="number">80.111</span></span><br><span class="line">ONBOOT=<span class="string">"yes"</span></span><br><span class="line">TYPE=<span class="string">"Ethernet"</span></span><br></pre></td></tr></table></figure></p>
<h3 id="5_配置LVS">5 配置LVS</h3><p>LVS主要配置virtual server和real server，以及开启IP转发。<br>ipvsadm的配置就不再多说，直接看man手册即可。<br>为了方便以后用，把ipvsadm命令组织到service脚本中，可以<code>service dlvs start/stop</code>。由于ipvsadm的配置不会保存，如果设备故障重启了就没了，需要把service start加到系统启动过程中。<br>脚本：<code>/etc/init.d/dlvs</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/sh</span></span><br><span class="line">VIP=<span class="number">10.80</span>.<span class="number">1.243</span></span><br><span class="line">RIP1=<span class="number">192.168</span>.<span class="number">80.167</span></span><br><span class="line">RIP2=<span class="number">192.168</span>.<span class="number">80.136</span></span><br><span class="line">SERVPORT=<span class="number">3306</span></span><br><span class="line">. /etc/rc.d/init.d/<span class="built_in">functions</span></span><br><span class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    start)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">" start DLVS of Director Server"</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/ip_forward</span><br><span class="line">        /sbin/ipvsadm -C</span><br><span class="line">        /sbin/ipvsadm -A -t <span class="variable">$VIP</span>:<span class="variable">$SERVPORT</span> <span class="operator">-s</span> rr</span><br><span class="line">        /sbin/ipvsadm <span class="operator">-a</span> -t <span class="variable">$VIP</span>:<span class="variable">$SERVPORT</span> -r <span class="variable">$RIP1</span>:<span class="variable">$SERVPORT</span> -m</span><br><span class="line">        /sbin/ipvsadm <span class="operator">-a</span> -t <span class="variable">$VIP</span>:<span class="variable">$SERVPORT</span> -r <span class="variable">$RIP2</span>:<span class="variable">$SERVPORT</span> -m</span><br><span class="line">        service iptables stop</span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"close DLVS Director Server"</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"0"</span> &gt;/proc/sys/net/ipv4/ip_forward</span><br><span class="line">        /sbin/ipvsadm -C</span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Usage: <span class="variable">$0</span> &#123;start|stop&#125;"</span></span><br><span class="line">        <span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></p>
<p>将脚本启动加到系统启动过程中。在centos里，需要把用户自己启动的命令加到/etc/rc.local中，即在这个文件中添加一行：<code>service dlvs start</code>。</p>
<h3 id="6_测试">6 测试</h3><p>DLVS1、DLVS2、RS1、RS2正常启动后，虚IP1、虚IP2均落在DLVS1上（使用ip addr命令）。DLVS1、DLVS2上看lvs内核表项均为：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ipvsadm -l</span></span><br><span class="line">IP Virtual Server version <span class="number">1.2</span>.<span class="number">1</span> (size=<span class="number">4096</span>)</span><br><span class="line">Prot LocalAddress:Port Scheduler Flags</span><br><span class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span><br><span class="line">TCP  <span class="number">10.80</span>.<span class="number">1.243</span>:mysql rr</span><br><span class="line">  -&gt; <span class="number">192.168</span>.<span class="number">80.136</span>:mysql         Masq    <span class="number">1</span>      <span class="number">0</span>          <span class="number">0</span></span><br><span class="line">  -&gt; master:mysql                 Masq    <span class="number">1</span>      <span class="number">1</span>          <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>从客户端PC访问虚IP1（10.80.1.243），DLVS1将请求NAT到mysql服务器中的某一台，在DLVS1上可以看到ipvs连接信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ipvsadm -l -c</span></span><br><span class="line">IPVS connection entries</span><br><span class="line">pro expire state       <span class="built_in">source</span>             virtual            destination</span><br><span class="line">TCP <span class="number">14</span>:<span class="number">53</span>  ESTABLISHED <span class="number">10.80</span>.<span class="number">0.243</span>:<span class="number">50640</span>  <span class="number">10.80</span>.<span class="number">1.243</span>:mysql  master:mysql</span><br></pre></td></tr></table></figure></p>
<p>将DLVS1整机重启，虚IP1、虚IP2漂移到DLVS2上，客户端再访问mysql服务，会重建连接，在DLVS2上ipvsadm可以看到新建立的connection；DLVS1重启完毕后，连接会再建立到DLVS1上，前面已有描述，略。</p>
<h3 id="7_待扩展">7 待扩展</h3><h4 id="7-1_内核connection同步">7.1 内核connection同步</h4><p>从前面的例子我们可以看到，虚IP漂移后，DLVS2接手，但是客户端连接需要重新建立，但其实真实的mysql服务器还是正常工作的，对于用户来说连接断开的体验较差。<br>LVS可以通过配置，在内核提供一个同步线程，将当前提供服务的设备上的表项，组播报文同步到其他服务器上。配置如下：<br><figure class="highlight puppet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[@<span class="constant">D</span>LVS1]$: ipvsadm --<span class="literal">start</span>-daemon master - --mcast-<span class="keyword">interface</span> ethX</span><br><span class="line">[@<span class="constant">D</span>LVS2]$: ipvsadm --<span class="literal">start</span>-daemon <span class="literal">backup</span> - --mcast-<span class="keyword">interface</span> ethY</span><br></pre></td></tr></table></figure></p>
<p>虚IP切换过以后，内核连接信息都在，就可以保证用户连接不断。<br>但这里还有个问题，在本方案里，所有的LVS其实均为主，而组播线程其实是有主、备身份的，备切过去以后就不能再同步表项了，当主设备回切，连接还是会断。还没有想到办法解决。</p>
<h4 id="7-2_iptables">7.2 iptables</h4><p>细心的同学会发现前面我粗暴的把iptables服务给整个关闭了，但这其实是很不安全的，正确的做法是添加一条规则。<br>关闭的原因？在实测过程中，发现从mysql返回的syn+ack报文，被DLVS设备的防火墙丢弃并返回了”Destination unreachable (Host administratively prohibited)”。<br>等我知道该怎么添加规则的时候，我就改。</p>
<h4 id="7-3_ldirectord">7.3 ldirectord</h4><p>现在的方案里，如果是RS级别的故障，LVS可以做到切换，不会将服务NAT到故障的机器；但如果只是mysql服务的故障，LVS还做不到检查，会影响用户访问失败。所以，需要一个工具能够告诉LVS，RS上的服务故障了，不要再转过去了。<br>ldrectord可以搞定这件事情。</p>
<p>大量参考：<br><a href="http://ixdba.blog.51cto.com/2895551/552947" target="_blank" rel="external">Linux负载均衡软件LVS系列</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="需求">需求</h3><h3 id="1_安装软件">1 安装软件</h3><p>基本所有的Linux版本内核都包含了LVS，不需要再安装。<br>安装ipvsadm，用来控制内核lvs表项；<br>keepalived，用来控制虚IP迁移；<br>ldirect]]>
    </summary>
    
      <category term="keepalived" scheme="http://yoursite.com/tags/keepalived/"/>
    
      <category term="lvs" scheme="http://yoursite.com/tags/lvs/"/>
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[百度PALO技术整理分析]]></title>
    <link href="http://yoursite.com/2015/08/08/baidu-palo/"/>
    <id>http://yoursite.com/2015/08/08/baidu-palo/</id>
    <published>2015-08-08T05:39:26.000Z</published>
    <updated>2015-08-08T05:55:43.418Z</updated>
    <content type="html"><![CDATA[<p>以下内容基本源于百度PALO（OLAP分析引擎）对外的一个<a href="http://www.chinahadoop.cn/course/95/learn#lesson/1333" target="_blank" rel="external">视频演讲</a>，讲的比较形象，下面做了简单的摘抄。</p>
<p><strong>总体架构图</strong><br><img src="http://7xir15.com1.z0.glb.clouddn.com/palo_1.png" alt=""></p>
<p>PALO对外体现为一个mysql的服务器，所有mysql相关的工具：mysql client，JDBC，基于mysql的报表工具、R语言等，都可以直接对接PALO。<br>FE即Front End，PALO使用了RAFT协议来共享元数据，所有FE都可以接收用户请求。RAFT协议类似PAXOS(代表实现zookeeper)，但要简化很多。master故障后，follower可以根据checkpoint进行LOG回放，快速恢复元数据（内存数据库）。RAFT支持较好的横向扩展，observer就是这个作用。</p>
<p><strong>数据存储</strong><br>hash partition<br>指定表按某一列做hash分区。<br>elastic range partition<br>与hash的散列分布不同，range partition是将数据连续的分区。如何解决列的value范围无法预测的问题呢？开始的时候只有一个分区列，当数据量增长到某一临界点时，将数据平均的分成两份。后面继续类似的处理。这样数据可以比较均衡的分散到不同的分区中。range partition对where友好。</p>
<p><strong>动态rollup表</strong><br>发现如果用户经常只观察该表的某几个维度，则动态生成rollup表，新表里的维度表只有常用列，由于会有一定的合并，后续查找该表的速度会比较快</p>
<p><strong>Compation</strong><br>小批量插入的数据，文件越来越多，会导致查询性能越来越差。可以设置一个规则，每隔一段时间将一定批量的数据合并在一起，查询的数据块变少，并且索引更准确，可以提高性能</p>
<p><strong>行列存</strong><br>每块数据包含256行，快内列式存储，按块压缩。数据压缩比率不高，对于分析型的数据库来说，每次查询都要遍历所有数据库，效率低。<br>稀疏索引：数据的共同特征作为索引常驻内存（每个块对应一个索引），查询时先查索引，找到数据块以后再做解压缩。</p>
<p><strong>列式存储</strong><br>参考HBASE。带来的优势：<br>1、分析型数据库通常只涉及某些列，可以避免遍历所有数据，减少CPU/IO消耗。PALO采用的是列式存储。<br><img src="http://7xir15.com1.z0.glb.clouddn.com/palo_2.png" alt=""><br>2、存储：列的数据类型一致，压缩效率高<br><img src="http://7xir15.com1.z0.glb.clouddn.com/palo_3.png" alt=""><br>3、智能索引：PALO会为每一个数据库都生成min max sum，在where sum等计算的时候，可以大幅度提高性能。<br>4、复合分区<br><img src="http://7xir15.com1.z0.glb.clouddn.com/palo_4.png" alt=""></p>
<p><strong>库内分析</strong><br><img src="http://7xir15.com1.z0.glb.clouddn.com/palo_5.png" alt=""><br>区别于数据与计算分离，可以解决网络和前端分析机器 性能的瓶颈。要求数据库有计算能力。<br>方法：数据库提供UDF/UDAF/UDTF。</p>
<p><strong>向量执行引擎</strong><br><img src="http://7xir15.com1.z0.glb.clouddn.com/palo_6.png" alt=""><br>区别于遍历所有行、过滤、计算的模型，向量执行引擎可以将待计算的该列单独拿出来计算。带来的好处：<br>行式处理变为列式处理，避免了指令和数据的cache miss；<br>编译器友好，可以循环展开+分支预测</p>
<p><strong>数据导入</strong><br>PALO依赖于hadoop，数据必须得先上HDFS，然后分布式的将各个节点上的数据块导入到PALO，导入性能较好。<br>PALO不支持直接实时插入。</p>
<p><del>小批量更新、批量原子提交</del></p>
<p><strong>其他</strong></p>
<ul>
<li>分布式管理框架，故障快速切换、恢复</li>
<li>查询引擎：share-noting MPP，可扩展好</li>
<li>大表分布式join：<br>shuffle，即先hash partition，再做join，join数据量小，适合大量数据与大量数据之间join；<br>broadcast，适合大量数据与小批量数据之间join，小批量数据直接与大批量数据的所有分片做join</li>
<li>谓词下推<br>实际就是尽早的将where条件下沉到数据库（离数据源越近越好），通过索引可以提早过滤掉数据，减少分析的数据量</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>以下内容基本源于百度PALO（OLAP分析引擎）对外的一个<a href="http://www.chinahadoop.cn/course/95/learn#lesson/1333" target="_blank" rel="external">视频演讲</a>，讲的比较]]>
    </summary>
    
      <category term="PALO" scheme="http://yoursite.com/tags/PALO/"/>
    
      <category term="baidu" scheme="http://yoursite.com/tags/baidu/"/>
    
      <category term="olap" scheme="http://yoursite.com/tags/olap/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用nginx+keepalived实现RESTful API服务器的负载均衡和高可靠性]]></title>
    <link href="http://yoursite.com/2015/07/02/nginx-keepalived/"/>
    <id>http://yoursite.com/2015/07/02/nginx-keepalived/</id>
    <published>2015-07-02T14:08:53.000Z</published>
    <updated>2015-07-02T14:43:02.000Z</updated>
    <content type="html"><![CDATA[<p>核心需求是我们有一个RESTful API的服务集群，需要能够保证不管是web服务故障还是服务器整体故障，外部访问不会间断，并且在整体运行正常的时候，需要能够负载均衡。<br>业界比较常见的几个负载均衡方案有haproxy, nginx, lvs。有关这仨的比较，可以看<a href="http://www.csdn.net/article/2014-07-24/2820837" target="_blank" rel="external">这篇文章</a>。我这里选择的方案是nginx+keepalived。nginx做反向代理，可以实现负载均衡，如果后端的web服务故障了，nginx可以实现切换；但nginx本身存在单点故障，需要通过keepalived监测实现nginx的切换。</p>
<a id="more"></a>
<p>整体结构图<br><img src="http://7xir15.com1.z0.glb.clouddn.com/nginx反向代理.png" alt=""></p>
<h2 id="1、设置nginx-repo：">1、设置nginx.repo：</h2><p>我用的操作系统是centos6.5，如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">name=nginx repo</span><br><span class="line">baseurl=http://nginx.org/packages/centos/<span class="variable">$releasever</span>/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=<span class="number">0</span></span><br><span class="line">enabled=<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<p>如果是RHEL:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[nginx]</span><br><span class="line">name=nginx repo</span><br><span class="line">baseurl=http://nginx.org/packages/rhel/<span class="variable">$releasever</span>/<span class="variable">$basearch</span>/</span><br><span class="line">gpgcheck=<span class="number">0</span></span><br><span class="line">enabled=<span class="number">1</span></span><br></pre></td></tr></table></figure></p>
<h2 id="2、安装nginx、keepalived">2、安装nginx、keepalived</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ yum install nginx</span><br><span class="line">$ yum install keepalived</span><br></pre></td></tr></table></figure>
<p>安装完毕后两个服务都是停止的，需要start并加到系统启动服务中。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ chkconfig  nginx on</span><br><span class="line">$ chkconfig  keepalived on</span><br></pre></td></tr></table></figure></p>
<p>nginx启动后，默认会有一个http server，例如我这里访问的地址是<code>http://192.168.80.165</code>和<code>http://192.168.80.166</code>，两台服务器的地址。但实际上我不需要这俩web服务器，而是需要让nginx做反向代理，将http请求导引到我的RESTful API服务器上，配置下面会有提到。</p>
<h2 id="3、修改keepalived的配置文件">3、修改keepalived的配置文件</h2><p>配置文件的路径是<code>/etc/keepalived/keepalived.conf</code>。<br>master：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eth2   <span class="comment">#具体的网卡</span></span><br><span class="line">    virtual_router_id <span class="number">51</span></span><br><span class="line">    priority <span class="number">101</span></span><br><span class="line">    advert_int <span class="number">1</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_<span class="built_in">type</span> PASS</span><br><span class="line">        auth_pass <span class="number">1111</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        <span class="number">192.168</span>.<span class="number">80.111</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>slave：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eth4   <span class="comment">#具体的网卡</span></span><br><span class="line">    virtual_router_id <span class="number">51</span></span><br><span class="line">    priority <span class="number">100</span>     <span class="comment">#比master小</span></span><br><span class="line">    advert_int <span class="number">1</span></span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_<span class="built_in">type</span> PASS</span><br><span class="line">        auth_pass <span class="number">1111</span></span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        <span class="number">192.168</span>.<span class="number">80.111</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其他的virtual server等信息都删掉，那是给lvs用的。<br>配置完毕后，重启两台服务器上的keepalived进程，在master上可以看到我们配置的虚IP（ifconfig看不到）。将master上keepalived服务stop掉，可以看到虚IP跑到slave上了；再启动master上keepalived进程，虚IP会被master抢占回来，因为master的priority更大。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ip add</span></span><br><span class="line">...</span><br><span class="line"><span class="number">2</span>: eth2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="number">1500</span> qdisc pfifo_fast state UP qlen <span class="number">1000</span></span><br><span class="line">    link/ether <span class="number">00</span>:<span class="number">0</span>c:<span class="number">29</span>:<span class="number">73</span>:f6:<span class="number">15</span> brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet <span class="number">192.168</span>.<span class="number">80.165</span>/<span class="number">24</span> brd <span class="number">192.168</span>.<span class="number">80.255</span> scope global eth2</span><br><span class="line">    inet <span class="number">192.168</span>.<span class="number">80.111</span>/<span class="number">32</span> scope global eth2</span><br></pre></td></tr></table></figure></p>
<h2 id="4、使用脚本检测nginx服务">4、使用脚本检测nginx服务</h2><p>上面的配置可以保证keepalived关闭（例如服务器故障）时，虚IP自动切换；但有的时候可能只是web服务故障了，我们希望的是keepalived检测服务的状态，并且能够自动切换。这种情况可以用脚本来检测nginx服务状态，根据检测结果调高或调低vrrp的优先级，达到虚IP切换的目的。<br>新建一个探测脚本：check_nginx.sh<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="shebang">#!/bin/bash</span></span><br><span class="line">netstat -antp|grep nginx</span><br><span class="line"><span class="built_in">exit</span> $?</span><br></pre></td></tr></table></figure></p>
<p>修改keepalived.conf：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">vrrp_script check_succ &#123;</span><br><span class="line">    script <span class="string">"/etc/keepalived/check_nginx.sh"</span></span><br><span class="line">    interval <span class="number">1</span></span><br><span class="line">    weight -<span class="number">5</span></span><br><span class="line">    fall <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">vrrp_script check_fail &#123;</span><br><span class="line">    script <span class="string">"/etc/keepalived/check_nginx.sh"</span></span><br><span class="line">    interval <span class="number">1</span></span><br><span class="line">    weight <span class="number">5</span></span><br><span class="line">    rise <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">...</span><br><span class="line">    track_script &#123;</span><br><span class="line">       check_succ</span><br><span class="line">       check_fail</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>据说探测成功或失败了以后只会改一次优先级，所以不要担心不停探测优先级一直增长的问题。<br>简单说明下，上面的脚本简单的检查了nginx是不是还在监听端口，如果发现不是（例如主的nginx被stop），则priority-5，vrrp通告出去后，备发现自己的优先级更高，vrrp切换，备抢占虚IP，此时访问的nginx就是备上的了；等到主nginx重新启动后，脚本检查端口已在监听，则priority+5，vrrp切换，主会重新抢占虚IP，达到HA的目的。</p>
<h2 id="5、配置nginx">5、配置nginx</h2><p>上面配置完keepalived后，HA的功能完成了，但是用户只能访问一个服务器，对于有多个web容器的情况就无能为力了，这时候需要nginx出马。<br>nginx在我们的组网里实际是一个loadbalance的角色，将用户的请求分发给不同的server（即upstream）。由于我们后端服务器监听的是8443 ssl端口，所以步骤稍微复杂一点。</p>
<h3 id="5-1_配置nginx">5.1 配置nginx</h3><p>CENTOS6.5的nginx配置是在<code>/etc/nginx/conf.d/default</code>，我直接给出配置（基本是照抄了以升的说明）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">upstream dxt</span><br><span class="line">&#123;</span><br><span class="line">        server <span class="number">192.168</span>.<span class="number">80.165</span>:<span class="number">8443</span>;   <span class="comment">#负载分担的两个服务器,</span></span><br><span class="line">        server <span class="number">192.168</span>.<span class="number">80.166</span>:<span class="number">8443</span>;   <span class="comment">#也就是我这里的rest api服务，分在两台服务器上</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen       <span class="number">443</span> ssl;			<span class="comment">#由于nginx和restapi服务在同一台服务器上，需要使用不同的端口</span></span><br><span class="line">    server_name  <span class="number">192.168</span>.<span class="number">80.111</span>;	<span class="comment">#虚IP</span></span><br><span class="line"></span><br><span class="line">    root html;</span><br><span class="line">    index index.html index.htm;</span><br><span class="line"></span><br><span class="line">    ssl on;							<span class="comment">#配置ssl</span></span><br><span class="line">    ssl_certificate server.crt;</span><br><span class="line">    ssl_certificate_key server.key;</span><br><span class="line">    ssl_session_timeout <span class="number">5</span>m;</span><br><span class="line"></span><br><span class="line">    ssl_protocols SSLv3 TLSv1 TLSv1.<span class="number">1</span> TLSv1.<span class="number">2</span>;</span><br><span class="line">    ssl_ciphers <span class="string">"HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES"</span>;</span><br><span class="line">    ssl_prefer_server_ciphers on;</span><br><span class="line"></span><br><span class="line">    location /api/ &#123;				<span class="comment">#只处理/api这个路径</span></span><br><span class="line">        proxy_<span class="built_in">set</span>_header X-Real-IP <span class="variable">$remote_addr</span>;</span><br><span class="line">        proxy_<span class="built_in">set</span>_header X-Forwarded-For <span class="variable">$proxy_add_x_forwarded_for</span>;</span><br><span class="line">        proxy_<span class="built_in">set</span>_header Host <span class="variable">$host</span>;</span><br><span class="line">        proxy_<span class="built_in">set</span>_header X-NginX-Proxy <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">        proxy_pass https://dxt;		<span class="comment">#指定upstream</span></span><br><span class="line">        proxy_redirect off;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="5-2_配置ssl需要的server-crt、server-key">5.2 配置ssl需要的server.crt、server.key</h3><p>使用ssl还需要两个证书文件，这里也按照以升给出的方法生成。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd /etc/nginx</span></span><br><span class="line"><span class="comment"># openssl genrsa -des3 -out server.key 1024</span></span><br><span class="line"><span class="comment"># openssl req -new -key server.key -out server.csr</span></span><br><span class="line"><span class="comment"># cp server.key server.key.org</span></span><br><span class="line"><span class="comment"># openssl rsa -in server.key.org -out server.key</span></span><br><span class="line"><span class="comment"># openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt</span></span><br></pre></td></tr></table></figure></p>
<p>配置后重启nginx，浏览器访问<code>https://192.168.80.111:443/api/</code>，应该可以看到restapi的信息了。</p>
<h3 id="5-3_坑">5.3 坑</h3><p>！！但是这里有个坑，如果你跟我一样也是用的centos6.5，会发现浏览器返回的是这样的：<br><img src="http://7xir15.com1.z0.glb.clouddn.com/nginx错误.png" alt="nginx错误信息"><br>说明还停留在nginx上，反向代理失败了。<br>去查nginx的日志<code>/var/log/nginx/error.log</code>，看到下面的信息：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2015</span>/<span class="number">07</span>/<span class="number">02</span> <span class="number">09</span>:<span class="number">52</span>:<span class="number">12</span> [error] <span class="number">15053</span><span class="comment">#0: *8 SSL_do_handshake() failed (SSL: error:100AE081:elliptic curve routines:EC_GROUP_new_by_curve_name:unknown group error:1408D010:SSL routines:SSL3_GET_KEY_EXCHANGE:EC lib) while SSL handshaking to upstream, client: 192.168.80.1, server: 192.168.80.111, request: "GET /api/ HTTP/1.1", upstream: "https://192.168.80.166:8443/api/", host: "192.168.80.111"</span></span><br></pre></td></tr></table></figure></p>
<p>查了一下，说这是centos6.5上默认openssl版本的错误，需要更新openssl的版本。可以查看<a href="http://zh.hortonworks.com/community/forums/topic/ambari-agent-registration-failure-on-rhel-6-5-due-to-openssl-2/" target="_blank" rel="external">这篇文章</a>，或者你懒的看，直接<code>yum update openssl</code>即可。<br>升级以后的版本应该是这个：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpm -aq|grep openssl</span></span><br><span class="line">openssl-<span class="number">1.0</span>.<span class="number">1</span>e-<span class="number">30</span>.el6.<span class="number">11</span>.x86_64</span><br></pre></td></tr></table></figure></p>
<p>升级完毕后再重启一下nginx，现在访问虚IP，就能看到restapi的信息了。如果你用POSTMAN这种restapi客户端打几次请求，从rest server日志里可以看到是轮询访问不同的rest server。<br><img src="http://7xir15.com1.z0.glb.clouddn.com/虚IP.png" alt=""></p>
<hr>
<p>通过上面的keepalived和nginx的配置，我们完成了开始预设的要求：<br>1、rest server能够负载分担；<br>2、某rest server进程故障，可以由nginx剔除；<br>3、nginx故障，keepalived可以切换虚IP到正常nginx，由新的nginx继续负载分担；nginx故障恢复，切换回原来的主server；<br>4、整设备故障，vrrp超时切换虚IP到正常服务器；故障恢复，回切。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>核心需求是我们有一个RESTful API的服务集群，需要能够保证不管是web服务故障还是服务器整体故障，外部访问不会间断，并且在整体运行正常的时候，需要能够负载均衡。<br>业界比较常见的几个负载均衡方案有haproxy, nginx, lvs。有关这仨的比较，可以看<a href="http://www.csdn.net/article/2014-07-24/2820837">这篇文章</a>。我这里选择的方案是nginx+keepalived。nginx做反向代理，可以实现负载均衡，如果后端的web服务故障了，nginx可以实现切换；但nginx本身存在单点故障，需要通过keepalived监测实现nginx的切换。</p>]]>
    
    </summary>
    
      <category term="keepalived" scheme="http://yoursite.com/tags/keepalived/"/>
    
      <category term="nginx" scheme="http://yoursite.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hibernate之Hello World]]></title>
    <link href="http://yoursite.com/2015/06/10/hibernate-hello/"/>
    <id>http://yoursite.com/2015/06/10/hibernate-hello/</id>
    <published>2015-06-10T11:22:01.000Z</published>
    <updated>2015-06-10T11:30:11.066Z</updated>
    <content type="html"><![CDATA[<p>Hibernate是一个优秀的持久化框架，其主要功能是将内存里的瞬时状态，通过JDBC持久化到硬盘数据库上。Hibernate以面向对象的思想来解决数据库的问题，可以简化数据库的访问。<br>这篇文章通过一个简单的示例，来建立Hibernate的初步认识，较水，记录用。<br><a id="more"></a></p>
<p>示例代码基本是从这篇<a href="http://www.javaweb.cc/architecture/hibernate/132325.shtml" target="_blank" rel="external">文章</a>里抄来的。</p>
<p>首先，得有一个<del>女朋友</del>表。我在mytest数据库里创建了一个student表。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`student`</span> (</span><br><span class="line">  <span class="string">`id`</span> <span class="built_in">int</span>(<span class="number">11</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> auto_increment,</span><br><span class="line">  <span class="string">`name`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">default</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="string">`password`</span> <span class="built_in">varchar</span>(<span class="number">255</span>) <span class="keyword">default</span> <span class="literal">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> <span class="keyword">KEY</span>  (<span class="string">`id`</span>)</span><br><span class="line">) ;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="1、创建工程，导入Hibernate库。">1、创建工程，导入Hibernate库。</h3><p>我下载的版本是4.3.10，从<a href="http://hibernate.org/orm/downloads/" target="_blank" rel="external">官方网站</a>上下载下来的是Hibernate ORM（hibernate-release-4.3.10.Final.zip）。要导入的lib文件在<code>.\hibernate-release-4.3.10.Final\lib\required\</code>，其他的先不管（我也不知道干啥用的）。<br>想不起来当时怎么把lib导入到IDEA了，现在导入没有图标了。</p>
<h3 id="2、建立包com-xxx-hibernatest">2、建立包<code>com.xxx.hibernatest</code></h3><h3 id="3、建立实体类的映射">3、建立实体类的映射</h3><p>在hibernatest包里新建Student.hbm.xml文件，编写对象关系映射文件，把对象关系映射的逻辑放在此处，这个文件包括表和字段的对象关系，当操作对象时，该文件通过java反射机制产生的方法，会把对象的方法转为关系的方法。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="pi">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="doctype">&lt;!DOCTYPE hibernate-mapping PUBLIC</span><br><span class="line">        "-//Hibernate/Hibernate Mapping DTD 3.0//EN"</span><br><span class="line">        "http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd"&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="title">hibernate-mapping</span> <span class="attribute">package</span>=<span class="value">"com.dtdream.hibernatest"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="title">class</span> <span class="attribute">name</span>=<span class="value">"Student"</span> <span class="attribute">table</span>=<span class="value">"student"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">id</span> <span class="attribute">name</span>=<span class="value">"id"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">generator</span> <span class="attribute">class</span>=<span class="value">"native"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="title">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"name"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"age"</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">class</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="title">hibernate-mapping</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="4、对象类定义。">4、对象类定义。</h3><p>在hibernatest包里新建Student.java。它对应于数据库的一个具体的表，需要定义数据库的列、列方法等，实际就是用Java来描述表。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.dtdream.hibernatest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Student</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span>  <span class="keyword">int</span> age;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> id;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getAge</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> age;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setId</span><span class="params">(<span class="keyword">int</span> id)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAge</span><span class="params">(<span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="5、main入口">5、main入口</h3><p>这里可以看到Hibernate简单的用法，代码看一看很清楚，就不多说了，名字随便起。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.dtdream.hibernatest;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.hibernate.Session;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.SessionFactory;</span><br><span class="line"><span class="keyword">import</span> org.hibernate.cfg.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StudentTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Student s = <span class="keyword">new</span> Student();</span><br><span class="line">        <span class="comment">//s.setId();	这句不需要，我们创建的数据库是increasement的</span></span><br><span class="line">        s.setAge(<span class="number">23</span>);</span><br><span class="line">        s.setName(<span class="string">"dtd"</span>);</span><br><span class="line"></span><br><span class="line">        Configuration cfg = <span class="keyword">new</span> Configuration();</span><br><span class="line">        SessionFactory sf = cfg.configure().buildSessionFactory();</span><br><span class="line">        Session session = sf.openSession();</span><br><span class="line">        session.beginTransaction();</span><br><span class="line">        session.save(s);</span><br><span class="line">        session.getTransaction().commit();</span><br><span class="line">        session.close();</span><br><span class="line">        sf.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="6、Hibernate主配置">6、Hibernate主配置</h3><p>前面我们有了数据库操作主流程，有了对象关系映射文件，有了表的对象，表在前面也创建了，那么就剩下怎么访问数据库了：地址、端口号、数据库名、driver。<br>这里提供一个<code>hibernate.cfg.xml</code>的数据库配置文件。配置文件放到工程的根目录，不要放到包里。<br>Hibernate实际是封装了JDBC，需要对应数据库的driver lib，对端数据库用的是mysql，所以需要把mysql-connector-java-5.1.35-bin也加到project的lib库里。<br>配置文件就不说了，照着葫芦画瓢就行。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="pi">&lt;?xml version='1.0' encoding='utf-8'?&gt;</span></span><br><span class="line"><span class="doctype">&lt;!DOCTYPE hibernate-configuration PUBLIC</span><br><span class="line">        "-//Hibernate/Hibernate Configuration DTD 3.0//EN"</span><br><span class="line">        "http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">hibernate-configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">session-factory</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Database connection settings --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"connection.driver_class"</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"connection.url"</span>&gt;</span>jdbc:mysql://192.168.5.29:3306/mytest<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"connection.username"</span>&gt;</span>root<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"connection.password"</span>&gt;</span><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- JDBC connection pool (use the built-in) --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"connection.pool_size"</span>&gt;</span>1<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- SQL dialect --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"dialect"</span>&gt;</span>org.hibernate.dialect.MySQLDialect<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Enable Hibernate's automatic session context management --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"current_session_context_class"</span>&gt;</span>thread<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Disable the second-level cache  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"cache.provider_class"</span>&gt;</span>org.hibernate.cache.internal.NoCacheProvider<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Echo all executed SQL to stdout --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"show_sql"</span>&gt;</span>true<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Drop and re-create the database schema on startup --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">property</span> <span class="attribute">name</span>=<span class="value">"hbm2ddl.auto"</span>&gt;</span>update<span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">mapping</span> <span class="attribute">resource</span>=<span class="value">"com/dtdream/hibernatest/Student.hbm.xml"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">session-factory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">hibernate-configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>好了，有了上面4个文件，一个简单的Hibernate示例就完成了，run main文件，我们去看mysql数据库里，可以看到添加了一条记录：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from student;</span><br><span class="line">+----+--------+----------+------+</span><br><span class="line">| id | name   | password | age  |</span><br><span class="line">+----+--------+----------+------+</span><br><span class="line">|  1 | dtd    | NULL     |   23 |</span><br><span class="line">+----+--------+----------+------+</span><br><span class="line">1 rows in set (0.01 sec)</span><br></pre></td></tr></table></figure></p>
<p>再运行一次，可以看到又添加了一条记录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from student;</span><br><span class="line">+----+--------+----------+------+</span><br><span class="line">| id | name   | password | age  |</span><br><span class="line">+----+--------+----------+------+</span><br><span class="line">|  <span class="number">1</span> | dtd    | NULL     |   <span class="number">23</span> |</span><br><span class="line">|  <span class="number">2</span> | dtd    | NULL     |   <span class="number">23</span> |</span><br><span class="line">+----+--------+----------+------+</span><br><span class="line"><span class="number">2</span> rows <span class="keyword">in</span> <span class="built_in">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure></p>
<p>至此，示例结束，以后有机会用Hibernate做一些实际的事情再来分享更深入的东西。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Hibernate是一个优秀的持久化框架，其主要功能是将内存里的瞬时状态，通过JDBC持久化到硬盘数据库上。Hibernate以面向对象的思想来解决数据库的问题，可以简化数据库的访问。<br>这篇文章通过一个简单的示例，来建立Hibernate的初步认识，较水，记录用。<br>]]>
    
    </summary>
    
      <category term="hibernate" scheme="http://yoursite.com/tags/hibernate/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[MapReduce具体问题（二）]]></title>
    <link href="http://yoursite.com/2015/06/02/mr-detail-2/"/>
    <id>http://yoursite.com/2015/06/02/mr-detail-2/</id>
    <published>2015-06-02T15:09:19.000Z</published>
    <updated>2015-06-02T15:11:47.000Z</updated>
    <content type="html"><![CDATA[<p>前一篇文章解答了Map任务数、启动人的细节，下面我们解答第二个问题：<br>HDFS的block是否粗暴但忠实的将文件按照64MB分片呢？如果是的话，怎么保证Map获取到的Splits是正确的？具体到wordcount，MR是怎么处理一个单词跨block的情况呢？</p>
<a id="more"></a>
<p>我们从Map任务的人口开始说起。前面YARN分析的时候有提到过，AppMaster会将task提交到NodeManager，在NM的container里运行具体的任务。具体到MR来说，运行的任务就是MapTask/ReduceTask。<br>来看MapTask的runNewMapper：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">runNewMapper</span><span class="params">(<span class="keyword">final</span> JobConf job,</span><br><span class="line">                    <span class="keyword">final</span> TaskSplitIndex splitIndex,</span><br><span class="line">                    <span class="keyword">final</span> TaskUmbilicalProtocol umbilical,</span><br><span class="line">                    TaskReporter reporter</span><br><span class="line">                    )</span> </span><br><span class="line">    org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt; inputFormat </span>=</span><br><span class="line">      (org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt;)	<span class="comment">//定义inputFormat</span></span><br><span class="line">        ReflectionUtils.newInstance(taskContext.getInputFormatClass(), job);</span><br><span class="line">..</span><br><span class="line">    org.apache.hadoop.mapreduce.RecordReader&lt;INKEY,INVALUE&gt; input =</span><br><span class="line">      <span class="keyword">new</span> NewTrackingRecordReader&lt;INKEY,INVALUE&gt;</span><br><span class="line">        (split, inputFormat, reporter, taskContext);	<span class="comment">//源自inputFormat</span></span><br><span class="line">..</span><br><span class="line">    mapContext = </span><br><span class="line">      <span class="keyword">new</span> MapContextImpl&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;(job, getTaskID(), </span><br><span class="line">          input, output, 	<span class="comment">//注意input</span></span><br><span class="line">          committer, </span><br><span class="line">          reporter, split);</span><br><span class="line"></span><br><span class="line">    org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;.Context </span><br><span class="line">        mapperContext = </span><br><span class="line">          <span class="keyword">new</span> WrappedMapper&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;().getMapContext(</span><br><span class="line">              mapContext);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      input.initialize(split, mapperContext);	<span class="comment">//先init</span></span><br><span class="line">      mapper.run(mapperContext);				<span class="comment">//再run</span></span><br></pre></td></tr></table></figure></p>
<p>runNewMapper会先new一个mapContext，然后封装为mapperContext，并将这个context传递给mapper的run方法。显然这里只是封装上下文，并不会处理跨分片。继续来看Mapper类的run方法。<br>用户会继承Mapper类，实现自己的setup和map方法，而run方法通常直接用Mapper的。来看Map框架的run方法：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Mapper</span>&lt;<span class="title">KEYIN</span>, <span class="title">VALUEIN</span>, <span class="title">KEYOUT</span>, <span class="title">VALUEOUT</span>&gt; </span>&#123;</span><br><span class="line">..</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    setup(context);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">while</span> (context.nextKeyValue()) &#123;		<span class="comment">//关键点</span></span><br><span class="line">        map(context.getCurrentKey(), context.getCurrentValue(), context);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>简单来说就是context不断的<code>nextKeyValue</code>，得到了KV交给用户自定义的map方法。那么解决问题的关键就在nextKV了。<br>Mapper的run方法里用的是Context，具体nextKeyValue是在哪个类里定义的，还得回去MapTask里找<code>MapContextImpl</code>。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MapContextImpl</span>&lt;<span class="title">KEYIN</span>,<span class="title">VALUEIN</span>,<span class="title">KEYOUT</span>,<span class="title">VALUEOUT</span>&gt; </span><br><span class="line">..</span><br><span class="line">  <span class="title">public</span> <span class="title">MapContextImpl</span>(<span class="title">Configuration</span> <span class="title">conf</span>, <span class="title">TaskAttemptID</span> <span class="title">taskid</span>,</span><br><span class="line">                        <span class="title">RecordReader</span>&lt;<span class="title">KEYIN</span>,<span class="title">VALUEIN</span>&gt; <span class="title">reader</span>,</span><br><span class="line">                        <span class="title">RecordWriter</span>&lt;<span class="title">KEYOUT</span>,<span class="title">VALUEOUT</span>&gt; <span class="title">writer</span>,</span><br><span class="line">                        <span class="title">OutputCommitter</span> <span class="title">committer</span>,</span><br><span class="line">                        <span class="title">StatusReporter</span> <span class="title">reporter</span>,</span><br><span class="line">                        <span class="title">InputSplit</span> <span class="title">split</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(conf, taskid, writer, committer, reporter);</span><br><span class="line">    <span class="keyword">this</span>.reader = reader;	<span class="comment">//reader</span></span><br><span class="line">    <span class="keyword">this</span>.split = split;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="annotation">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> reader.nextKeyValue();	<span class="comment">//调用reader的nextKeyValue</span></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>MapTask在创建上下文的时候记录reader类型，等到Mapper.run调用上下文的nextKeyValue的时候，实际调用的是reader的nextKV。<br>那么reader是谁呢？回到<code>runNewMapper</code>方法，reader其实就是input，而input的类型就是解析输入文件的后缀名得到的；在wordcount示例里，输入是纯文本文件，实际就是TextInputFormat。<br><code>runNewMapper</code>的<code>NewTrackingRecordReader</code>调用了<code>TextInputFormat</code>的<code>createRecordReader</code>，最终创建了<code>LineRecordReader</code>对象。</p>
<p>答案就在LineRecordReader里。来看代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LineRecordReader</span> <span class="keyword">implements</span> <span class="title">RecordReader</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">LineRecordReader</span><span class="params">(Configuration job, FileSplit split,	//record初始化方法</span><br><span class="line">      <span class="keyword">byte</span>[] recordDelimiter)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(InputSplit genericSplit,</span><br><span class="line">                         TaskAttemptContext context)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">...</span><br><span class="line">    <span class="comment">// If this is not the first split, we always throw away first record</span></span><br><span class="line">    <span class="comment">// because we always (except the last split) read one extra line in</span></span><br><span class="line">    <span class="comment">// next() method.</span></span><br><span class="line">    <span class="keyword">if</span> (start != <span class="number">0</span>) &#123;		<span class="comment">//只要不是第一个分片，总是跳过第一行，因为前面的block处理的时候，已经越过分区读取完毕了</span></span><br><span class="line">      start += in.readLine(<span class="keyword">new</span> Text(), <span class="number">0</span>, maxBytesToConsume(start));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.pos = start;		<span class="comment">//记录本分split的起始位置</span></span><br><span class="line">  &#125;</span><br><span class="line">...</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>) &#123;</span><br><span class="line">      key = <span class="keyword">new</span> LongWritable();</span><br><span class="line">    &#125;</span><br><span class="line">    key.set(pos);</span><br><span class="line">    <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">      value = <span class="keyword">new</span> Text();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> newSize = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// We always read one extra line, which lies outside the upper</span></span><br><span class="line">    <span class="comment">// split limit i.e. (end - 1)</span></span><br><span class="line">    <span class="keyword">while</span> (getFilePosition() &lt;= end || in.needAdditionalRecordAfterSplit()) &#123;	<span class="comment">//保证到了split末尾时只会一次“超读”</span></span><br><span class="line">      <span class="keyword">if</span> (pos == <span class="number">0</span>) &#123;</span><br><span class="line">        newSize = skipUtfByteOrderMark();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        newSize = in.readLine(value, maxLineLength, maxBytesToConsume(pos));	<span class="comment">//答案：超读</span></span><br><span class="line">        pos += newSize;</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>还记得刚开始的<code>runNewMapper</code>里是怎么处理的吗？对，先initialize，再run；run里不停的nextKeyValue。<br>具体到LineRecordReader，initialize的处理是，如果当前块不是首块，那么就会跳过第一行（Split的划分其实是逻辑上的，只是指定了该文件的start和end位置，而不是真实的划分成小文件），因为第一行已经在前面的块里处理了；<br>相应的，在NextKeyValue里，由于使用的是readLine，故而总是会读完该文件的一整行（而不是该split），如果是该行跨HDFS分区，那么就读取下一个分区。</p>
<p>答案其实很简单，不过借着这个问题，梳理了下MapTask的流程，虽然有点琐碎，但还是有所收获。<br>若分析谬误，还请指出:)</p>
<p>参考：<br><a href="http://my.oschina.net/xiangchen/blog/99653" target="_blank" rel="external">Hadoop MapReduce中如何处理跨行Block和InputSplit</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>前一篇文章解答了Map任务数、启动人的细节，下面我们解答第二个问题：<br>HDFS的block是否粗暴但忠实的将文件按照64MB分片呢？如果是的话，怎么保证Map获取到的Splits是正确的？具体到wordcount，MR是怎么处理一个单词跨block的情况呢？</p>]]>
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[python学习作业（二）]]></title>
    <link href="http://yoursite.com/2015/05/28/python-homework-2/"/>
    <id>http://yoursite.com/2015/05/28/python-homework-2/</id>
    <published>2015-05-28T15:11:15.000Z</published>
    <updated>2015-05-28T15:51:30.000Z</updated>
    <content type="html"><![CDATA[<p>需求：生成纯文本格式的表数据，导入ODPS/ADS等。用户可以定义表的格式。<br>最早是想找一个类似DataFactory的工具来做，但今天问了下史进是自己用Java写的，走读了一遍逻辑不太复杂，于是花了些时间写了一个python版本的。</p>
<p>实现思路非常简单：配置文件使用json格式，python读取配置文件，按每一行的格式随机生成内容，每行生成后写入文件，最后关闭文件，结束。<br><a id="more"></a></p>
<p>几个有意思的点：</p>
<ul>
<li>json配置文件怎么写注释？json本身并没有定义注释，但是可以像本例一样加一个注释字段，占坑但不拉翔。</li>
<li>随机字符串的生成。<code>GenStr</code>的实现是从网上找到一个方法稍作修改：先随机生成若干字符，然后join。不知道是否有更高效的实现方法？</li>
<li>随机时间的生成，我这里的做法是取当前时间的浮点表示值，然后取比这个小的一个随机值，最后将其转为时间格式。</li>
<li>类似<code>switch case</code>的编码风格。python不支持switch，原因<a href="https://docs.python.org/2/faq/design.html#why-isn-t-there-a-switch-or-case-statement-in-python" target="_blank" rel="external">见这里</a>。我这里也是参考网上的一个做法，定义函数数组，效率比<code>if...elif...elif</code>应该高一点。</li>
</ul>
<p>配置文件cfg.json：<br><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  "<span class="attribute">filename</span>" : <span class="value"><span class="string">"test.txt"</span></span>,</span><br><span class="line">  "<span class="attribute">table</span>":</span><br><span class="line">  <span class="value">&#123;</span><br><span class="line">    "<span class="attribute">lines</span>" : <span class="value"><span class="string">"30"</span></span>,</span><br><span class="line">    "<span class="attribute">_commet_for_columes</span>" : <span class="value"><span class="string">"colume type support BOOLEAN, BIGINT, DOUBLE, STRING, DATATIME only."</span></span>,</span><br><span class="line">    "<span class="attribute">columes</span>":<span class="value"><span class="string">"BIGINT, STRING, DATETIME, BOOLEAN, DOUBLE"</span></span><br><span class="line">  </span>&#125;</span><br><span class="line"></span>&#125;</span><br></pre></td></tr></table></figure></p>
<p>生成数据gendata.py：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">staticChars = string.ascii_letters+string.digits</span><br><span class="line">staticCharLen = len(staticChars)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GenBoolean</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> str(random.randint(<span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GenBigInt</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> str(random.randint(<span class="number">0</span>, sys.maxint))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GenDouble</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> str(random.uniform(<span class="number">0</span>, sys.maxint))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GenStr</span><span class="params">()</span>:</span></span><br><span class="line">    length = random.randint(<span class="number">1</span>, staticCharLen)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join([random.choice(staticChars) <span class="keyword">for</span> i <span class="keyword">in</span> range(length)])</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GenDate</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> time.strftime(<span class="string">"%Y-%M-%d"</span>, time.localtime(random.uniform(<span class="number">0</span>,time.time())))</span><br><span class="line"></span><br><span class="line">funcs = &#123;</span><br><span class="line">    <span class="string">"BOOLEAN"</span>: GenBoolean,</span><br><span class="line">    <span class="string">"BIGINT"</span> : GenBigInt,</span><br><span class="line">    <span class="string">"DOUBLE"</span> : GenDouble,</span><br><span class="line">    <span class="string">"STRING"</span> : GenStr,</span><br><span class="line">    <span class="string">"DATETIME"</span> : GenDate</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GenData</span><span class="params">(ctype)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> funcs[ctype.upper().strip()]()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    f = file(<span class="string">"cfg.json"</span>)</span><br><span class="line">    jscfg = json.load(f)</span><br><span class="line"></span><br><span class="line">    lines = int(jscfg[<span class="string">u'table'</span>][<span class="string">u'lines'</span>])</span><br><span class="line">    columes = str(jscfg[<span class="string">u'table'</span>][<span class="string">u'columes'</span>]).split(<span class="string">','</span>)</span><br><span class="line"></span><br><span class="line">    filep = file(jscfg[<span class="string">u'filename'</span>], <span class="string">'w'</span>)</span><br><span class="line">    <span class="keyword">while</span> lines &gt; <span class="number">0</span>:</span><br><span class="line">        lines -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> type <span class="keyword">in</span> columes:</span><br><span class="line">            filep.write(GenData(type) + <span class="string">','</span>)</span><br><span class="line">        filep.write(<span class="string">'\n'</span>)</span><br><span class="line">    filep.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>需求：生成纯文本格式的表数据，导入ODPS/ADS等。用户可以定义表的格式。<br>最早是想找一个类似DataFactory的工具来做，但今天问了下史进是自己用Java写的，走读了一遍逻辑不太复杂，于是花了些时间写了一个python版本的。</p>
<p>实现思路非常简单：配置文件使用json格式，python读取配置文件，按每一行的格式随机生成内容，每行生成后写入文件，最后关闭文件，结束。<br>]]>
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
</feed>