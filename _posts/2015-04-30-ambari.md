---
layout: post
title: "Ambari简介"
date: 2015-04-30 11:10:59
tags: ambari
author: 伊布
categories: tech
cover:  "/assets/instacode.png"
---


###1 介绍
之前搭建hadoop平台（参加[前一篇blog](http://silenceshell.github.io/2015/04/24/hadoop-setup/)），采用的是手动安装、修改配置文件的方法。这样可以大致了解hadoop基本的部署过程，但是实际生产过程中不可能采用这种全手工的方法，后续还涉及到安装HBase/Hive/Spark/Storm之类的上层应用，以及管理监控平台，过程相对繁琐一些。
面对这些问题，就需要一个优秀的分布式集群管理工具了。目前了解到业界自动化部署+管理监控工具里，比较有名的是Hortonworks的[ambari](http://ambari.apache.org/)，以及cloudera的[cloudera manager](http://www.cloudera.com/content/cloudera/en/downloads/cloudera_manager/cm-5-4-0.html)。
<!--more-->
简单上两张图对比下管理界面：
ambari:
![](http://7xir15.com1.z0.glb.clouddn.com/ambari.png)
cloudera manager(官网上的图，后面等安装了CDH版本后再详细介绍吧 - -)：
![](http://www.cloudera.com/content/dam/cloudera/product-assets/manager-screenshots/manager-screenshot-3.jpg)

###2 架构详解
**暂时还没有深入了解，先挖个坑在这。**
感兴趣的同学可以先看CSDN上的一篇[文章](http://blog.csdn.net/shifenglov/article/details/42803283)，介绍的比较仔细。
简单来说，ambari利用了一些优秀的开源软件，做到了集群部署(puppet)、监控(Ganglia/nagios)、管理能力。

###3 安装
我用的是3台阿里云的ECS，centos6.5系统，直接从hortonworks官方源拖的。ambari将安装做的已经非常好了，无奈受限于网络状况，安装过程中可能会出现失败的情况，retry就好了。吐槽一下ECS，不知道阿里的网络带宽是怎么限制的，实际使用起来有时效果比较糟糕，同一个地址下载可能一台几十KB，另一台可以达到3MB/s。
下面简单写一下安装过程吧，网上教程搜一下很多，这儿就只说一下坑。
*建议直接参考[官方的安装说明](https://cwiki.apache.org/confluence/display/AMBARI/Installation+Guide+for+Ambari+2.0.0)*
####3.1 配置ssh免认证登陆、hosts
请参考前一篇blog。
####3.2 下载官方yum源

```
For Redhat/CentOS/Oracle:
  cd /etc/yum.repos.d/
  wget <ambari-repo-url>
```

**坑**：网上的教程多数还是基于1.x版本的，写blog的时候官方已经发布到了2.0.0（跳过了1.8/1.9）。
下载的repo url决定了使用的ambari版本，建议安装的时候去官网上找一下最新版本的repo url。
另，如果空间富裕的话，建议找一台虚机做一个官方源的镜像，后面安装会顺畅很多。
####3.3 install, setup, and start ambari-server
步骤简单，

```
yum install ambari-server
ambari-server setup
ambari-server start
```

安装完毕后访问`http://<ambari-server-host>:8080`，有ambari的登陆界面，密码是admin/admin。
![](http://7xir15.com1.z0.glb.clouddn.com/ambari登陆.PNG)

####3.4 安装hadoop/spark等服务
ambari提供了一个安装向导，按着来就行，具体可以参照chinaunix上的一篇[blog](http://blog.chinaunix.net/uid-26230811-id-4023821.html)，注意他用的是古老的1.4。
几个坑：
- 如果使用的是自己的镜像，需要在向导里就先修改为实际的镜像地址（需要关闭验证）。不要妄想这儿不改，等到安装各个服务的时候跑到`/etc/yum.repos.d/
`里去改，安装向导会强行覆盖的。
- 如果用的是比较老的比如1.4的版本，注册这一步可能会提示用的版本不匹配。

```
Cluster primary OS type is redhat6 and local OS type is centos5 Local OS is not compatible with cluster primary OS. Please perform manual bootstrap on this host.
```

是安装脚本问题([AMBARI-4101](https://issues.apache.org/jira/secure/attachment/12620503/AMBARI-4101.patch))，可以按patch修改`os_type_check.sh`。我的办法是强行修改current_os与cluster一致。当然，直接上2.0吧，新版本已经改了这个bug了。

- 要求输入各主机名列表时，务必使用FQDN格式（即`www.google.com`之类），不能直接使用benzema/bale这种。
- 向导要求提供的是私钥，跟ssh免认证登陆不同（Q:为什么要私钥？）
- 如果安装各个服务的时候，失败的实在太多，可以先把包下载下来，手动安装。ambari retry对于已经安装过的只会检查。
- 如果不幸，你先安装了低版本的ambari，没关系，ambari是支持升级的，具体参考[官方指导文档](http://docs.hortonworks.com/HDPDocuments/Ambari-2.0.0.0/Ambari_Doc_Suite/Ambari_Upgrade_v20.pdf)。如果不幸升级失败了，可以ambari-server reset全部复位掉。
- 想起来再补

###4 验证
####4.1 验证HDFS
登陆到HDFS的master控制台

```bash
[root@ty10 ~]# hadoop fs -ls /
Found 8 items
drwxrwxrwt   - yarn   hadoop          0 2015-04-29 15:42 /app-logs
drwxr-xr-x   - hdfs   hdfs            0 2015-04-28 15:55 /apps
drwxr-xr-x   - hdfs   hdfs            0 2015-04-28 15:50 /hdp
...
```

####4.2 验证spark on yarn
到安装spark client的主机上跑一下spark的示例应用：

```bash
spark-submit --class org.apache.spark.examples.SparkPi     --master yarn-cluster      --num-executors 3      --driver-memory 2g     --executor-memory 2g     --executor-cores 1        lib/spark-examples*.jar    10
```

yarn上查看application：
![](http://7xir15.com1.z0.glb.clouddn.com/ambari_spark_e1.PNG)

spark上查看任务：
![](http://7xir15.com1.z0.glb.clouddn.com/ambari_spark_ui.PNG)






