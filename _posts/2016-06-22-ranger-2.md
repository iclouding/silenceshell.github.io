---
layout: post
title: "Apache Ranger续：与LDAP和Kerberos合作，提供统一的认证、管理"
date: 2016-06-22 00:11:12
author: 伊布
categories: tech
tags: ranger
cover:  "/assets/instacode.png"
---

* TOC
{:toc}

### 1、全集群使用LDAP做用户管理

Ranger 0.5版本开始支持使用LDAP做认证，即除了Ranger自己的internal用户，在LDAP中的用户也可以登录Ranger系统去做权限管理；而Ranger的user-sync也支持从LDAP同步用户到Ranger。用户管理完全在LDAP中管理，授权完全在Ranger中管理，Ranger操作的用户为从LDAP中同步过来的用户（LDAP中删除用户，不会影响Ranger）。

这两者有无依赖关系呢？我尝试把user-sync服务关闭，然后在LDAP中增加用户，这个用户是可以登录到Ranger中的，证明Ranger使用LDAP认证，不需要将用户先同步过来，二者是解耦的。

Ranger-admin、Ranger-usersync的安装步骤完全参考[官网](https://cwiki.apache.org/confluence/display/RANGER/Apache+Ranger+0.5.0+Installation#ApacheRanger0.5.0Installation-InstallandconfigureSolrorSolrCloud)，官网文档写的非常好，*这里只记录与官网文档有所出入的地方*。与官网不同的是我的audit没有使用solr，而是使用db，所以需要填写DB的用户名、密码，以及在Mysql DB中为这个用户增加权限。

```
mysql> GRANT ALL PRIVILEGES ON *.* TO 'rangeradmin'@'%' IDENTIFIED BY '{rangeradmin passwd}' WITH GRANT OPTION;
mysql> GRANT ALL PRIVILEGES ON *.* TO 'rangerlogger'@'%' IDENTIFIED BY '{rangerlogger passwd}' WITH GRANT OPTION;
mysql> FLUSH PRIVILEGES;
```

同时在install.properties中加配置：

```
db_name=ranger
db_user=rangeradmin
db_password={rangeradmin passwd}

audit_db_name=ranger_audit
audit_db_user=rangerlogger
audit_db_password={rangerlogger passwd}
```

### 2、管理hive授权


**暂时不要用Ranger 0.6 snapshot。麻蛋改了checkPrivileges的接口，会报java.lang.AbstractMethodError: org.apache.ranger.authorization.hive.authorizer.RangerHiveAuthorizer.checkPrivileges**

Ranger-hive-plugin的安装参考上面官网说明。唯一不同的是官网是以hive安装到/usr/local目录为准的，如果你的hive安装目录不在这，可以参照我改的enable-hive-plugin.sh：


```
#HCOMPONENT_INSTALL_DIR=`(cd ${hdir} ; pwd)`
HCOMPONENT_INSTALL_DIR=/home/dtdream/hive/apache-hive-2.0.0-bin
..
#HCOMPONENT_CONF_DIR=${HCOMPONENT_INSTALL_DIR}/conf
HCOMPONENT_CONF_DIR=/home/dtdream/hive/apache-hive-2.0.0-bin/conf
```

关键的配置是这个：

```xml
    <property>
        <name>hive.security.authorization.manager</name>
        <value>org.apache.ranger.authorization.hive.authorizer.RangerHiveAuthorizerFactory</value>
    </property>
```

需要修改conf/hive-env.sh，指定Hive需要加载的extra jar包，否则hiveserver2启动时会报Classnotfound上面设置的RangerHiveAuthorizerFactory类：

```bash
# Folder containing extra ibraries required for hive compilation/execution can be controlled by:
export HIVE_AUX_JARS_PATH=/usr/local/ranger-hive-plugin/lib/*:/usr/local/ranger-hive-plugin/lib/ranger-hive-plugin-impl/*
```

多说一句，spark启动时使用-cp加载jar包，会遇到指定jar包目录不生效的情况，在目录/后加上*就好使了。我理解是-cp和-classpath是有区别的，classpath可以加载目录，但看到很多材料上都说二者没有任何不同，摊手。

```bash
$ java -help
..
    -cp <class search path of directories and zip/jar files>
    -classpath <class search path of directories and zip/jar files>
                  A : separated list of directories, JAR archives,
                  and ZIP archives to search for class files.
```

配置完成后，我们使用数据库管理员dtdream（而不是ranger的管理员admin）为普通用户gan在hivedev增加policy，允许其访问某些数据。设置policy到生效中间有一点延迟。另，Hive配置为Ranger管理后，就不能再使用SQLStandAuthorization了（很好理解对吧）。


### 3、管理spark thrift server授权

Spark 1.6官方版本直接不支持，默认还是hive cli的身份，不会走给Ranger。我打上[之前文章](http://www.datastart.cn/tech/2016/06/21/kerberos-3.html)最后提到的PR，能将授权交给Ranger处理，但由于sessionstate是我自己new出来的，Ranger在取objectActionType的时候取不到，会Null失败，等改好了再说吧，TODO。

### 4、Final Fantasy

基本上能够解决平台安全和数据安全的需求。

![spark security](http://7xir15.com1.z0.glb.clouddn.com/spark_security.png)

