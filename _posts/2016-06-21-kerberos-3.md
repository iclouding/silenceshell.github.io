---
layout: post
title: "Kerberos从入门到放弃（二）：kerberos+LDAP各司其职"
date: 2016-06-21 00:11:11
author: 伊布
categories: tech
tags: kerberos, ldap
cover:  "/assets/instacode.png"
---


前面2篇Kerberos文章
[HDFS使用kerberos](http://www.datastart.cn/tech/2016/06/07/kerberos-1.html)、[YARN、Spark、Hive使用kerberos](http://www.datastart.cn/tech/2016/06/11/kerberos-2.html)介绍了在spark/hadoop集群开启Kerberos后可以获得的好处：

- 服务认证，如YARN的namenode、datanode，spark thrift server使用yarn的资源
- 用户认证，如使用不同的Principal登录到spark thrift server

由于集群一般来说变化的比较小，服务认证比较合适；但在多租户的集群上，Kerberos这种需要独占操作系统静态kinit自己的Principal的方式，完全无法接受；另一方面，企业、开源组件中较多使用LDAP做认证，Kerberos比较小众，因此比较好的方式是Kerberos+LDAP，LDAP作为总的用户认证中心，使用thrift server的用户通过LDAP做认证。

在前面knox中我们简单介绍了超级简单的ApacheDS LDAP Server，不过它在生产环境中显然是不合适的。这里我们采用的是openLDAP，国内如美团使用的是freeIPA，它集成了Kerberos、LDAP、sso等功能，有机会后面使用下看看效果如何。

下面记录了Spark thrift server使用LDAP做认证的几个步骤，比较简单。

1、
ubuntu上安装openLDAP比较简单，`sudo apt-get install slapd ldap-utils`即可，安装过程中会要求输入管理员密码。

2、
安装之后，重新配置slapd，`sudo dpkg-reconfigure slapd`，需要回答一系列问题，由于ubuntu使用了dialog，不方便记录，下面直接照抄[斗大的熊猫](http://blog.topspeedsnail.com/archives/2981)的记录：

Omit OpenLDAP server configuration?  回答No

DNS domain name:  基于输入的domain创建基本的目录结构，我使用zelda.com。

Organization name: 我使用spark。

Administrator password: 安装时候输入的密码，或使用新密码。

Database backend to use:   HDB

removed when slapd is purged? No

Move old database? Yes

Allow LDAPv2 protocol? No

我在这里创建了dc=zelda,dc=com的domain。

3、
与熊猫同学后面使用了phpLDAPadmin这种BS架构的管理工具不同，我使用的是在前面[knox文章](http://www.datastart.cn/tech/2016/06/17/knox.html)中介绍的LDAP Admin（CS），优点是windows客户端方便，缺点是不甚稳定，出现过几次假死、显示不全的问题。对于企业客户来说，使用类似phpLDAPadmin这种web客户端可能更合适，不需要强制用户安装客户端。当然你这么帅气也可以使用命令行。

我增加了1个ou=platform，2个uid=gan,uid=dtdream，并设置密码使用SHA1加密保存。其中ou是new了一个Organizational unit，而uid是new了一个entry（不是user！不是user！不是user！），在其中指定Object Class、cn、sn、uid；Rdn形式为'uid=gan'。


```
objectclass:top
objectclass:person
objectclass:organizationalPerson
objectclass:inetOrgPerson
cn: DtDream
sn: User
uid: dtdream
```

这样我们就有了一个普通用户gan，下面在登录thriftserver的时候会用到。

4、
LDAP的配置完成，下面改下spark thrift server使用LDAP做认证：

```xml
<!--
<property>
  <name>hive.server2.authentication</name>
  <value>KERBEROS</value>
</property>
-->
<property>
  <name>hive.server2.authentication.kerberos.principal</name>
  <value>dtdream/_HOST@ZELDA.COM</value>
</property>
<property>
  <name>hive.server2.authentication.kerberos.keytab</name>
  <value>/etc/security/dtdream.zelda1.keytab</value>
</property>

<property>
  <name>hive.server2.authentication</name>
  <value>LDAP</value>
</property>
<property>
  <name>hive.server2.authentication.ldap.url</name>
  <value>ldap://zelda3.zelda.com:389</value>
</property>
<property>
  <name>hive.server2.authentication.ldap.baseDN</name>
  <value>ou=platform,dc=zelda,dc=com</value>
</property>
```

2点说明：

1. 虽然我们使用LDAP做认证，但由于我们是Kerberos集群，thrift server要能在集群中跑起来，还是需要Kerberos Principal的，不能连带keytab的2个配置一起注释掉。
2. baseDN，需要指定ou=platform，否则beeline登录时会说我是LDAP认证你给我个PLAIN的认证我是不肯的（Peer indicated failure: PLAIN auth failed: Error validating LDAP user）。

5、
重启spark thrift server，使用beeline登录，用户名、密码即为beeline登录时要求用户输入的username、password。

这样我们的spark thirft server就可以通过LDAP来做认证了，结合SQL Based Authorization或者Ranger，可以针对不同用户授予不同权限以达到数据隔离的目的。

ps：
默认的spark thrift server只能使用storage based authorization，原因是没有为设置SessionState是hiveServerQuery：  `ss.setIsHiveServerQuery(true)`。可以参考spark的[这个PR](https://github.com/apache/spark/pull/11045/files)，对thrift server配置使用SQL Based Authorization（AuthorizationV2）。原来的PR有2个bug，如果你想试用的话可以邮件咨询我，代码就不贴了。不过作者只实现了SELECT的检查，实测对INSERT不起作用，任何用户都可以INSERT。授权，在我看来还是Ranger这种比较合适，统一管理。

