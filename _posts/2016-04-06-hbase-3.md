---
layout: post
title: "HBase分布式部署（三）"
date: 2016-04-06 09:21:00
author: 伊布
categories: tech
tags: hbase
cover:  "/assets/instacode.png"
---

当前环境HBASE全分布式部署，使用外置ZK。由于全分布式部署，要求底层存储必须使用HDFS，不能像standalone那样使用本地文件。注意由于部署的时候没有做记录，可能有所疏漏。

### 安装HDFS

HDFS/YARN等都打在hadoop一个包中，不是单独的一个包。我这里只是部署了一个简单的HDFS集群，没有考虑name node的HA问题。我用的是HADOOP 2.6.3。另外我仍然还没有配置yarn。

部署基本参考了 [这篇文章](http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide/#single-node-test)，下面简单记录下。

1、在spark1（就是我的AG）上修改这2个文件：

**hdfs-site.xml**
指定namenode和datanode的路径：

```
<configuration>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:///home/dtdream/hadoop/hadoop-2.6.3/hdfs/datanode</value>
        <description>for datanode.</description>
    </property>

    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:///home/dtdream/hadoop/hadoop-2.6.3/hdfs/namenode</value>
        <description>for namenode.</description>
    </property>
</configuration>

```

**core-site.xml**
为各个datanode指定namenode。standalone模式的HDFS，这里指定的是localhost。

```
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://spark1/</value>
        <description>NameNode URI</description>
    </property>
</configuration>
```

2、修改spark1上的./etc/hadoop/slaves文件，添加spark2/spark3/spark4，每行一条

3、然后将hadoop目录整个拷贝到spark2/spark3/spark4，保持配置一致。

4、启动HDFS集群。

```
$HADOOP_PREFIX/bin/hdfs namenode -format
$HADOOP_PREFIX/sbin/start-dfs.sh
```

5、检查是否好用
使用./bin/hadoop fs -xxx命令行来上传、查看、下载文件；也可以在`http://spark1:50070`的WEB UI中查看HDFS的状态、浏览HDFS上的数据。


### 安装HBASE

HBase的部署分为standalone、伪分布式、全分布式。前两者hbase的所有组件都在同一台机器上，不符合生成环境的要求，需要全分布式来部署。

HBase的组件有如下几个：

- HMaster
- HMaster Backup
- Region Server
- ZK

由于我在装spark的时候已经安装了一套ZK，所以HBASE就没有再重复来一套了，部署的时候需要指定外部zk。另外我没有部署HMaster Backup。


1、指定HBASE为分布式
修改.conf/hbase-site.xml

```
<property>
  <name>hbase.cluster.distributed</name>
  <value>true</value>
</property>
```

2、指定HBASE的存储使用HDFS
修改.conf/hbase-site.xml

```
<property>
  <name>hbase.rootdir</name>
  <value>hdfs://spark1:8020/hbase</value>
</property>
```


3、指定HABSE使用外部ZK，顺便修改JAVA_HOME

修改conf/hbase-env.sh，其中HBASE_MANAGES_ZK若为false，则HBASE不会启动它自带的zk。

```
export JAVA_HOME=/usr/  
export HBASE_MANAGES_ZK=false
```

4、指定外部ZK的路径
修改.conf/hbase-site.xml

```
<property>
  <name>hbase.zookeeper.quorum</name>
  <value>spark1,spark11,spark12</value>
</property>
```

5、更新regionserver列表
将spark2/spark3/spark4按行添加到conf/regionservers中。

6、调大ZK的连接数
使用中发现默认ZK允许的连接数很小，导致spark4无法跟ZK建连接。修改zk目录下的conf/zoo.cfg，设置maxClientCnxns=1000，重启ZK。


7、启动HBASE

使用`bin/start-hbase.sh`可以启动整个HBASE集群。

8、验证
除了按照第一篇文章中验证HBase功能，还可以在HDFS中看到/hbase中的一些文件。我这里在spark2/3/4上均配置了HBASE和HDFS，但我不确定HBASE是不是有比较好的本地性。

```
./hadoop fs -ls /hbase
Found 9 items
drwxr-xr-x   - dtdream supergroup          0 2016-04-07 03:26 /hbase/.tmp
drwxr-xr-x   - dtdream supergroup          0 2016-04-07 03:26 /hbase/MasterProcWALs
drwxr-xr-x   - dtdream supergroup          0 2016-04-07 03:26 /hbase/WALs
drwxr-xr-x   - dtdream supergroup          0 2016-04-07 00:55 /hbase/archive
drwxr-xr-x   - dtdream supergroup          0 2016-04-07 00:36 /hbase/corrupt
drwxr-xr-x   - dtdream supergroup          0 2016-04-07 00:36 /hbase/data
-rw-r--r--   3 dtdream supergroup         42 2016-04-07 00:24 /hbase/hbase.id
-rw-r--r--   3 dtdream supergroup          7 2016-04-07 00:24 /hbase/hbase.version
drwxr-xr-x   - dtdream supergroup          0 2016-04-07 04:26 /hbase/oldWALs
```

HBASE也提供了WEB UI，可以访问`http://spark1:16010`，在这里可以看到HBASE所有的Region Server、表详情。

### 数据导入HBASE

分为直接导入和转为HFile导入两种情况。

> todo.




