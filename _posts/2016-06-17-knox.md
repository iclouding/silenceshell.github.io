---
layout: post
title: "使用Apache Knox配置保护Spark/Hadoop"
date: 2016-06-17 00:11:11
author: 伊布
categories: tech
tags: knox
cover:  "/assets/instacode.png"
---


* TOC
{:toc}

我们知道Spark、HDFS等等都提供了Story Web UI，用户可以从Web上查看当前JOB的执行情况，也可以kill掉JOB。那么这个Web UI不应该所有人都可以访问，而应该只开放给管理员使用。默认Spark没有认证，能连接到这个集群上就可以访问Web UI，但通过Knox，可以在打开Web UI的时候先做认证，限制只有某些用户可以访问。
类似的，Knox还可以保护HDFS NN UI、Yarn UI等，具体参考[这里](https://knox.apache.org/books/knox-0-9-0/user-guide.html#UI+Service+Details)。


另外我们访问Spark SQL主要通过thriftserver，从前面的文章我们可以配置thrift server使用Kerberos、LDAP、CUSTOM中的任意一种来做保护，但Knox还提供了另一种思路，用户访问入口在Knox上，认证也由Knox来做（跟上面Web UI一样）。集群内部不需要任何认证。

Apache Knox Gateway是一个用于hadoop安全的RESTful API Gateway，为Spark/Hadoop集群提供唯一的REST入口。Knox以类似防火墙的形式挡在Spark集群之前，接管所有用户请求（如WEB UI访问、HDFS内容查看、Hive/HBase数据操作等）。从拓扑上来说这种做法更清爽（相对Kerberos），但对内部集群的保护要求很高，因为一旦攻破了Knox层，不管资源还是数据都是光着屁股的。


Apache Knox提供如下功能：

- Authentication (LDAP and Active Directory Authentication Provider)
- Federation/SSO (HTTP Header Based Identity Federation)
- Authorization (Service Level Authorization)
- Auditing

我们主要用Knox来保护Spark UI、HDFS UI、Yarn UI，以及thrift server。当然，Knox也不只是服务于Hadoop、Spark，对于Web化的应用，基本上都可以使用Knox做保护，例如[用Knox做Tomcat代理](http://blog.csdn.net/tonyhuang_google_com/article/details/50038165)，主要是定义service.xml和rewrite.xml，即处理哪些url、如何处理。

Knox也支持Kerberos保护的集群。不过我这里使用了未启动Kerberos的集群，先忽略。

官网的图画的很形象。下面会以Spark UI和Thrift server为例说明如何使用Knox。

![knox topo](http://knox.apache.org/images/knox-overview.gif)



### 启动自带LDAP

如官网图，Knox做认证使用的是LDAP，当然你可以用openLDAP、AD，不过我这里试用，直接使用了Knox自带的demo性质的ldap服务器：ApacheDS LDAP server，解压knox-{version}.zip包就可以得到。


启动：`./bin/ldap.sh start/stop`
配置文件1：./bin/ldap.cfg，指定main.class和jar包路径

```
main.class=org.apache.hadoop.gateway.security.ldap.SimpleLdapDirectoryServer
class.path=../lib/*.jar
```

配置文件2：./conf/user.ldif，指定ldap层级，默认knox带的LDAP demo里已经内置了dn=hadoop.apache.org，并且配置了少量用户、组，我就直接用了。

介绍几个LDAP的概念：

- o– organization（组织-公司）
- ou – organization unit（组织单元-部门）
- c – countryName（国家）
- dc – domainComponent（域名）
- sn – suer name（真实名称）
- cn – common name（常用名称）

省事起见就直接用knox的配置了：

```
dn: dc=hadoop,dc=apache,dc=org
dn: uid=admin,ou=people,dc=hadoop,dc=apache,dc=org
dn: uid=guest,ou=people,dc=hadoop,dc=apache,dc=org
```

demo LDAP明文记录密码。openLDAP里记录的是加密后的密码，更安全。如果要保护用户与LDAP服务器的交互过程，可以开启LDAPS。

Windows上可以使用LdapAdmin客户端连接到LDAP服务器上。下图是我的连接配置和打开连接以后看到的默认存在的用户。demo LDAP默认端口号是33389。

![LdapAdmin](http://7xir15.com1.z0.glb.clouddn.com/ldapadmin.PNG)


### 创建Master key

创建master key以保护knox实例里保存的key和credential。

```
cd {GATEWAY_HOME}
bin/knoxcli.sh create-master
```

### 配置Gateway

配置文件为`conf/gateway-site.xml`。由于使用的是没有开启Kerberos的集群，这个文件不需要修改。不过需要注意gateway.path这个参数，后面调用Knox的RESTful API时会用到，作为第一层路径。

```xml
    <property>
        <name>gateway.path</name>
        <value>gateway</value>
        <description>The default context path for the gateway.</description>
    </property>
```

### 配置Spark UI代理

Knox可以定义多个Topologies，在conf/topologies/目录中增加xml文件即为一个topo，结合上面的gateway.path，一个RESTful API如下：

```
https://192.168.181.73:8443/gateway/sandbox/sparkhistory
```

其中sandbox就是一个topo，对应topologies目录中的sandbox.xml文件。默认不包含spark ui，我们在里面添加一个service：

```xml
<service>
    <role>SPARKHISTORYUI</role>
    <url>http://localhost:8080/</url>
</service>
```

Apache Knox 0.9版本开始支持spark history UI，你可以参看/data/service/sparkhistoryui里的servcice.xml和rewrite.xml文件，对配置自己web应用会有帮助吧。

重启knox，从chrome访问`https://192.168.181.73:8443/gateway/sandbox/sparkhistory`，会提示输入用户名、密码，这里我用的是guest。

> 需要关注如何对不同的service配置不同的用户级别或者组。


### 配置HiveServer2代理

*麻蛋蚊子太多了明天再写*








