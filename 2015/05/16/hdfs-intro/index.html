<!DOCTYPE HTML>
<html>
<head>
  <meta name="baidu-site-verification" content="mFmscoluqW" />
  <meta charset="utf-8">
  
  <title>Hadoop文件系统：HDFS | 伊布</title>
  <meta name="author" content="hubt@dtdream.com">
  
  <meta name="description" content="1 概述HDFS应用场景：存储超大型流式处理数据（Terabytes和Petabytes级别）。总的来说，HDFS的特点有这么几个：

“write once, read many”，只支持一个writer，但对并发的reader支持很高的吞吐。
将数据处理逻辑放置到数据附近，可以减少数据拷贝的成本，提高并发效率。下面的读取/写入，都体现了这个特点。
可靠：维护同一文件的的多个副本+故障发生时自动重新部署问题节点。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Hadoop文件系统：HDFS"/>
  <meta property="og:site_name" content="伊布"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/github.ico" rel="icon" type="image/x-ico">
  <link rel="alternate" href="/atom.xml" title="伊布" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?28bfa356a7c60e170822a01142cf208e";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>

<script>
var option = {
  engineKey: 'f3e1951e888b8a117845'
};
(function(w,d,t,u,n,s,e){
  s = d.createElement(t);
  s.src = u;
  s.async = 1;
  w[n] = function(r){
    w[n].opts = r;
  };
  e = d.getElementsByTagName(t)[0];
  e.parentNode.insertBefore(s, e);
})(window,document,'script','//tinysou-cdn.b0.upaiyun.com/ts.js','_ts');
_ts(option);
</script>

</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">伊布</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/About">About</a></li>
    
	<li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-05-15T16:56:26.000Z"><a href="/2015/05/16/hdfs-intro/">2015-05-16</a></time>
      
      
  
    <h1 class="title">Hadoop文件系统：HDFS</h1>
  

    </header>
    <div class="entry">
      
        <h3 id="1_概述">1 概述</h3><p>HDFS应用场景：存储超大型流式处理数据（Terabytes和Petabytes级别）。<br>总的来说，HDFS的特点有这么几个：</p>
<ul>
<li>“write once, read many”，只支持一个writer，但对并发的reader支持很高的吞吐。</li>
<li>将数据处理逻辑放置到数据附近，可以减少数据拷贝的成本，提高并发效率。下面的读取/写入，都体现了这个特点。</li>
<li>可靠：维护同一文件的的多个副本+故障发生时自动重新部署问题节点。</li>
</ul>
<a id="more"></a>
<p>从这几个不能满足的要求，可以反过来看HDFS的特点：</p>
<ul>
<li>低延迟的数据访问。HDFS关注的是数据吞吐量，强调整个文件。</li>
<li>大量的小文件。HDFS设计为支持大文件，大量的小文件会造成namenode负载沉重。</li>
<li>多用户写入，任意修改文件。只支持一个writer，且只能写到文件的最后（流式处理）。</li>
<li>随机数据访问。</li>
</ul>
<h3 id="2_架构">2 架构</h3><ul>
<li>name node：管理文件系统命名空间和访问权限，记录了data node的数据块的位置（注意是在内存里，不保存，每次data node加入时重建）。</li>
<li>data node：将数据作为块存储在文件里。</li>
</ul>
<p><img src="http://www.ibm.com/developerworks/cn/web/wa-introhdfs/fig1.gif" alt=""><br>HDFS架构如上图。name node可以识别data node的机架ID，从而优化data node之间的通信，减少跨机架的通信，因为通常这比同一机架的通信要慢。</p>
<h4 id="块">块</h4><p>类似传统文件系统，HDFS也有<strong>块</strong>的概念，默认为64MB，但通常会被设置为128MB（跟硬盘读写速度相关）。数据存储到块文件里去。<br>块如此之大的原因：HDFS读取的吞吐率取决于2个方面：寻址的速度、块读取的速度。块设计的大一些，可以最小化寻址开销，尽可能接近硬盘的读取速度（极限情况：设计为只有一块，完全是硬盘的读取速度）。但不能将块设置太大，否则数据块的个数变少，会造成Map任务并发不够。<br>att：如果块存放的数据比块要小，实际并没有完全占用块。<br>使用块的优点：可以支持超大文件（经历过1080P拷贝到FAT32移动硬盘的同学会懂其中的痛）；相对管理文件来说，管理块更简单；可以做容错、负载分担。</p>
<h4 id="文件访问权限">文件访问权限</h4><p>如下例，hdfs跟POSIX非常像。hdfs的用户，实际就是远程客户端操作时候的用户，比如下面我用test上传了一个文件上去，其用户就是test，不管其他节点上是否也有test用户。hdfs的’x’权限，只是表示”该目录可进入“，没有”执行“这个概念。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[<span class="built_in">test</span>@master conf]$ hadoop fs -put core-site.xml  /tmp/</span><br><span class="line">[<span class="built_in">test</span>@master conf]$ hadoop fs -ls /tmp/</span><br><span class="line">Found <span class="number">5</span> items</span><br><span class="line">drwxrwxrwx   - hdfs   supergroup          <span class="number">0</span> <span class="number">2015</span>-<span class="number">05</span>-<span class="number">11</span> <span class="number">22</span>:<span class="number">28</span> /tmp/.cloudera_health_monitoring_canary_files</span><br><span class="line">-rw-r--r--   <span class="number">3</span> <span class="built_in">test</span>   supergroup       <span class="number">3849</span> <span class="number">2015</span>-<span class="number">05</span>-<span class="number">14</span> <span class="number">19</span>:<span class="number">10</span> /tmp/core-site.xml</span><br><span class="line">..</span><br></pre></td></tr></table></figure></p>
<p>新版本的hadoop使用了kerberos来做认证。</p>
<h3 id="3_文件读取">3 文件读取</h3><h4 id="3-1_访问接口">3.1 访问接口</h4><p>hdfs提供了多种访问方式。<br>方式一：我们在客户端使用<code>hadoop fs -ls /</code>的操作，实际就是一个应用程序调用hdfs的java api接口实现的。<br>方式二：hdfs还提供了一个libhdfs的C语言库，可以通过JNI来访问；其他一些语言，例如c++, ruby, python等等可以通过<a href="http://dongxicheng.org/search-engine/thrift-framework-intro/" target="_blank" rel="external">thrift</a>代理来访问。thrift是个比较神奇的东西，后面可以好好玩一下。<br>方式三：hdfs提供了web浏览服务，下文提到的distcp就是利用了这一方式，其优势在于没有版本兼容的顾虑。</p>
<h4 id="3-2_客户端读取HDFS过程">3.2 客户端读取HDFS过程</h4><p><img src="http://upload.news.cecb2b.com/2014/1108/1415426527715.jpg?_=42872" alt=""><br>这个过程中，name node负责处理block位置的请求，客户端获得位置信息后，直接与data node联系，避免name node称为瓶颈。读取有下面两个特点</p>
<ul>
<li>距离最近。读取datanode时，有一个“距离最近”的概念。name node返回存储该块的data node列表，dfs的datanode管理对象会从距离最近的datanode读取该数据块。该块read完毕后，继续请求下一块数据，直到读取完毕。</li>
<li>容错。datanode管理对象会校验读取数据，如果出错，会从其他最近的节点重新读取块，并且在读取下一block时通知name node。</li>
</ul>
<p>那么距离是怎么定义的呢？可以将网络看成一棵树，两个节点的距离就是他们到最近的共同祖先的距离之和。根据数据中心、机架、节点，可以定义不同层级；对于复杂的网络，需要用户帮助hadoop来定义其拓扑。</p>
<h3 id="4_文件写入">4 文件写入</h3><p>参考下面的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.fs.FileSystem hdfs = org.apache.hadoop.fs.FileSystem.get(config);</span><br><span class="line">org.apache.hadoop.fs.Path path = <span class="keyword">new</span> org.apache.hadoop.fs.Path(filePath);</span><br><span class="line">org.apache.hadoop.fs.FSDataOutputStream outputStream = hdfs.create(path);</span><br><span class="line">outputStream.write(fileData, <span class="number">0</span>, fileData.length);</span><br></pre></td></tr></table></figure></p>
<p>首先在name node文件系统的命名空间里创建一个新文件，注意这时还没有真正的数据块（实际就是一个记录）。<br>然后，数据被分为一个个数据包，一次性写入“数据队列”；数据队列的处理器会向name node请求得到一组data node作为一个“管道”；数据流式写入管道的第一个data node，然后再由这个节点同步给其他data node。<br><img src="http://upload.news.cecb2b.com/2014/1108/1415426527902.jpg?_=6898" alt=""><br>只要有一个datanode写入成功就可以，集群会自行异步复制到其他节点。</p>
<blockquote>
<p>问题：“管道”申请是每文件，还是每block？</p>
</blockquote>
<p>name node是怎么选择data node来做副本写入呢？布局策略有很多，默认策略是这样的：先在写入数据的客户端本地存储一份（如果客户端不在HDFS集群上，则随机选择一个集群节点），然后在其他另一机架上选择2个节点各存储一份，再有副本就随机选择了。<strong>只要写入一个data node成功，写操作就会成功，客户端调用只需要等待最小量的复制。</strong><br>该策略很好的平衡了可靠性（跨机架）、写入带宽（只需考虑本地交换机）、读取带宽（两个机架），数据均匀分布。</p>
<p><strong>数据一致性</strong><br>创建文件后，命名空间立即可见；但写入数据不能立即可见。应用程序需要自己权衡写入吞吐量和鲁棒，自行决定什么时候sync同步缓存。另外，文件关闭<code>close()</code>隐含了sync方法，需要所有数据写入datanode才能确认返回。</p>
<p>这里再谈一下客户端提交数据的过程。考虑这样一个问题：客户端读取小的日志并写入hdfs，每读取一条调用write，是否就引起写入hdfs一次？实际上客户端会建立一个临时本地文件，写入数据会被重定向到这个临时文件，直到满足一个数据块的大小；之后关闭临时文件，才会真正将此数据提交到hdfs上。</p>
<h3 id="5_可靠">5 可靠</h3><p><strong>data node心跳</strong><br>data node需要有间隔的向name node发送心跳，如果心跳丢失，name node将该data node设置为不可用，如果导致副本低于<strong>复制因子</strong>，还需要将该data node上的数据块复制到其他的data node上。</p>
<p><strong>数据块再平衡</strong><br>情景一：当某些data node上的空闲空间太小时，hdfs会自动移动。<br>情景二：新增data node时。可以考虑手动平衡<code>hadoop balance</code>。</p>
<p><strong>数据完整</strong><br>对hdfs上的文件会存储checksum到文件系统命名空间的隐藏文件中；客户端取到数据后会检验这个checksum是否正确。</p>
<p><strong>元数据同步</strong><br>我们需要先了解几个概念，否则下面要讲的就完全看不懂了。<br>EditLog：一个记录文件系统命名空间的变换，例如文件重命名，权限修改，文件创建，数据块定位等等的持久化的文件。修改玩EditLog后，客户端的调用才会返回。<br>fsImage：实际就是文件系统周期性的还原点，也是持久化的。在fsImage基础之上，回放EditLog，可以得到最新的文件系统。<br>数据块位置记录：跟上面两个不同，存放在内存。name node启动时根据data node的报告重建。</p>
<p>简单的来说，name node的文件系统命名空间，权限，文件与数据块的映射关系，存储在fsImage文件中；所有用户对hdfs的操作，存放在EditLog文件中。hdfs对这些元数据文件可以做多副本（如写到远端NFS）。</p>
<p><strong>secondary namenode</strong><br>与namenode不同，主要工作是将命名空间fsImage和EditLog融合，并记录融合后的image，防止EditLog过大。其EditLog的同步滞后于name node。<br>name node故障后的过程如下：</p>
<ul>
<li>将NFS上的image拷贝到secondary namenode上，加载到内存</li>
<li>重放EditLog记录的操作</li>
<li>收集足够的data node报告，重新建立数据块的映射关系</li>
<li>离开safe mode，成为正式的name node。</li>
</ul>
<p>这一过程在大集群中可能会到几十分钟。</p>
<p><strong>HA</strong><br>hadoop 2.x版本比较好的解决了name node的单点故障。<br>新版本引入了name node<strong>对</strong>，分别配置为master/standby。故障恢复需要的两个关键信息是这样处理的：<br><img src="http://pic002.cnblogs.com/images/2012/402771/2012120917500498.png" alt=""></p>
<ul>
<li>EditLog存放在NFS一类的共享存储中。master故障后，standby会立即重放EditLog，快速恢复状态。standby仍然运行着secondary namenode，用于融合image和EditLog。</li>
<li>datanode需要向master/standby同时报告，两个name node都有完整的数据块映射。</li>
</ul>
<p>据说只要几十秒就可以完成倒换。</p>
<h3 id="6_Fedoration">6 Fedoration</h3><p>引入了”域“的概念，允许集群不止有一个name node，但不同的name node共享同一个data node集群。<br>Fedoration可以解决集群变大时，name node成为瓶颈的问题，但是name node仍然存在单点故障，应属于一个过渡方案。不过Fedoration引入域以后，意外的获得了多租户的特性。</p>
<h3 id="7_小文件解决方案">7 小文件解决方案</h3><p><strong>归档工具</strong><br>archive可以克服大量小文件给namenode带来的内存压力，并且还能获得文件的透明访问。archive实际也是一个mr任务，需要hadoop集群。<br>[hdfs@master conf]$  hadoop archive -archiveName aaa.har -p /user/hdfs /user/hdfs<br>归档过程中是可以对文件进行压缩的，但是归档文件本身是不能压缩的。归档文件创建后不可更改，如果要删除或修改其中文件，只能重新归档。<br><strong>Sequence file</strong><br>由一系列KV组成，key为文件名，value为文件内容，将大批kv组成一个大文件。<br>这两种方案都需要用户应用程序干预，hdfs不会干预。</p>
<h3 id="8_distcp">8 distcp</h3><p>distcp是一个分布式并行的拷贝工具，实质是一个只有map的MR任务。通过制定map任务数(-m)，可以并行的将源文件拷贝到目标文件中。<br>相同版本的hdfs，distcp可以直接RPC拷贝；不同版本，则只能在目标hadoop上，通过http协议访问源dfs来并行的读取写入。<br><em>数据平衡性</em>：如果distcp -m 1，当文件很大的时候，由于只有一个map任务，那么写入的时候总是会写入该map任务所在的节点，这就带来不均衡，所以尽量选择更多的map任务。</p>
<p>最后回答前面的问题：是每block的，因为hdfs的目的就是为了存储大文件，如果是每文件，就只能固定存在3个节点上了。</p>
<p>参考：<br>Hadoop权威指南<br><a href="http://www.ibm.com/developerworks/cn/web/wa-introhdfs/" target="_blank" rel="external">IBM Developerworks</a><br><a href="http://www.cnblogs.com/beanmoon/archive/2012/12/11/2809315.html" target="_blank" rel="external">CSDN社区</a></p>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/hadoop/">hadoop</a>, <a href="/tags/hdfs/">hdfs</a>
  </div>

        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
	<div class="ds-thread"></div>
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"silenceshell"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
<form>
    <input type="text" id="ts-search-input"  name="word" maxlength="20"  class="search-form-input" placeholder="Search">
</form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">標籤</h3>
  <ul class="entry">
  
    <li><a href="/tags/PALO/">PALO</a><small>1</small></li>
  
    <li><a href="/tags/ambari/">ambari</a><small>1</small></li>
  
    <li><a href="/tags/baidu/">baidu</a><small>1</small></li>
  
    <li><a href="/tags/fullnat/">fullnat</a><small>2</small></li>
  
    <li><a href="/tags/hadoop/">hadoop</a><small>9</small></li>
  
    <li><a href="/tags/hdfs/">hdfs</a><small>1</small></li>
  
    <li><a href="/tags/hibernate/">hibernate</a><small>1</small></li>
  
    <li><a href="/tags/hive/">hive</a><small>1</small></li>
  
    <li><a href="/tags/keepalived/">keepalived</a><small>3</small></li>
  
    <li><a href="/tags/linux/">linux</a><small>1</small></li>
  
    <li><a href="/tags/lvs/">lvs</a><small>1</small></li>
  
    <li><a href="/tags/mesos/">mesos</a><small>1</small></li>
  
    <li><a href="/tags/mysql/">mysql</a><small>2</small></li>
  
    <li><a href="/tags/nginx/">nginx</a><small>1</small></li>
  
    <li><a href="/tags/olap/">olap</a><small>1</small></li>
  
    <li><a href="/tags/python/">python</a><small>2</small></li>
  
    <li><a href="/tags/spark/">spark</a><small>1</small></li>
  
    <li><a href="/tags/sqoop/">sqoop</a><small>1</small></li>
  
    <li><a href="/tags/storm/">storm</a><small>1</small></li>
  
    <li><a href="/tags/tez/">tez</a><small>1</small></li>
  
    <li><a href="/tags/yarn/">yarn</a><small>2</small></li>
  
  </ul>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 hubt@dtdream.com
  
</div>
<div class="clearfix"></div></footer>
  <script src="//libs.baidu.com/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>